{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5e2921a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import scvelo as scv\n",
    "from scvi.nn import Encoder, FCLayers\n",
    "import anndata\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import scanpy as sc\n",
    "from tqdm import tqdm\n",
    "from torch.distributions import Poisson, NegativeBinomial, kl_divergence, Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "96dcd9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0bb4176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_initialize_scvelo(\n",
    "    adata, \n",
    "    isoform_key=\"isoform_counts\", \n",
    "    proportion_key = \"proportion\",\n",
    "    min_isoform_counts=10, \n",
    "    min_cell_counts = 10,\n",
    "    min_isoform_prop=0.05, \n",
    "    n_top_genes=800,\n",
    "    n_top_splicing = 500,\n",
    "    min_cells_spanning = 5,\n",
    "    isoform_delimiter=\"_\",\n",
    "    normalized = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Prefilter Isoforms and Genes.\n",
    "    1. Filter cells, remove low total counts cells.\n",
    "    2. Filter Isoforms: Remove low expression and low global proportion isoforms.\n",
    "    3. Filter Genes, keep highly variable genes and isoform proportion variable genes.\n",
    "    4. Run scVelo dynamical mode.\n",
    "    5. Return initialization parameters for VAE.\n",
    "    \n",
    "    Parameters:\n",
    "    adata: including layers['unspliced'] and obsm[isoform_key]\n",
    "    isoform_key: key of isoform count in adata.obsm\n",
    "    \"\"\"\n",
    "\n",
    "    if adata.X is None:\n",
    "        adata.X = adata.layers['spliced'] + adata.layers['unspliced']\n",
    "\n",
    "    # 1. Filter cells, remove low total counts cells.\n",
    "    initial_cell_count = adata.n_obs\n",
    "    sc.pp.filter_cells(adata, min_counts=min_cell_counts)\n",
    "    print(f\"Filtered cells from {initial_cell_count} to {adata.n_obs} (min_counts={min_cell_counts})\")\n",
    "\n",
    "    # 2. Filter Isoforms: Remove low expression and low global proportion isoforms.\n",
    "    iso_df = adata.obsm[isoform_key]\n",
    "    iso_df = iso_df.loc[adata.obs_names]\n",
    "    isoform_names = iso_df.columns\n",
    "    try:\n",
    "        gene_map = pd.Series([x.rsplit(isoform_delimiter, 1)[0] for x in isoform_names], index=isoform_names)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error parsing isoform with names '{isoform_delimiter}'. Error: {e}\")\n",
    "\n",
    "    iso_sum = iso_df.sum(axis=0)\n",
    "    keep_mask_count = iso_sum >= min_isoform_counts\n",
    "\n",
    "    iso_prop = adata.obsm[proportion_key]\n",
    "    high_prop_mask = iso_prop >= min_isoform_prop\n",
    "    cells_passing_count = high_prop_mask.sum(axis=0)\n",
    "    keep_mask_prop = cells_passing_count >= min_cells_spanning\n",
    "    keep_isoforms = keep_mask_count & keep_mask_prop\n",
    "\n",
    "    filtered_iso_df = iso_df.loc[:, keep_isoforms]\n",
    "    adata.obsm[isoform_key] = filtered_iso_df\n",
    "    filtered_prop_df = iso_prop.loc[:, keep_isoforms]\n",
    "    adata.obsm[proportion_key] = filtered_prop_df\n",
    "\n",
    "    print(f\"Filtered isoforms from {iso_df.shape[1]} to {filtered_iso_df.shape[1]} based on isoform expression and global proportion.\")\n",
    "\n",
    "    remaining_isoforms = gene_map[keep_isoforms.values]\n",
    "    new_counts = pd.Series(remaining_isoforms).value_counts(sort=False)\n",
    "    adata.var['filtered_n_isoforms'] = 0\n",
    "    genes_to_update = new_counts.index.intersection(adata.var_names)\n",
    "    adata.var.loc[genes_to_update, 'filtered_n_isoforms'] = new_counts[genes_to_update]\n",
    "\n",
    "    # Recalculate proportion dataframe based on remaining isoforms\n",
    "    current_iso_cols = filtered_iso_df.columns\n",
    "    current_gene_map = pd.Series([x.rsplit(isoform_delimiter, 1)[0] for x in current_iso_cols], index=current_iso_cols)\n",
    "    new_gene_counts_df = filtered_iso_df.groupby(current_gene_map.values, axis=1).sum()\n",
    "    full_spliced_df = pd.DataFrame(\n",
    "        adata.layers['spliced'], \n",
    "        index=adata.obs_names, \n",
    "        columns=adata.var_names\n",
    "    )\n",
    "    full_spliced_df.update(new_gene_counts_df)\n",
    "    adata.layers['spliced'] = full_spliced_df.values\n",
    "    if not normalized:\n",
    "        adata.X = adata.layers['spliced'] + adata.layers['unspliced']\n",
    "\n",
    "    gene_ids_per_col = current_gene_map[filtered_iso_df.columns]\n",
    "    gene_counts_expanded = new_gene_counts_df.loc[:, gene_ids_per_col]\n",
    "    gene_counts_expanded.columns = filtered_iso_df.columns \n",
    " \n",
    "    new_props = filtered_iso_df / (gene_counts_expanded)\n",
    "    adata.obsm[proportion_key] = new_props\n",
    "      \n",
    "    # 3. Filter Genes, keep highly variable genes and isoform proportion variable genes.\n",
    "    adata_hvg = adata.copy()\n",
    "    if not normalized:\n",
    "        sc.pp.normalize_total(adata_hvg)\n",
    "        sc.pp.log1p(adata_hvg)\n",
    "        sc.pp.highly_variable_genes(adata_hvg, n_top_genes=n_top_genes, flavor='seurat')\n",
    "        hvg_genes = set(adata_hvg.var_names[adata_hvg.var['highly_variable']])\n",
    "    else:\n",
    "        sc.pp.highly_variable_genes(adata_hvg, n_top_genes=n_top_genes, flavor='seurat')\n",
    "        hvg_genes = set(adata_hvg.var_names[adata_hvg.var['highly_variable']])\n",
    "    \n",
    "    print(f\"Found {len(hvg_genes)} expression HVGs.\")\n",
    "\n",
    "    iso_variances = new_props.var(axis=0)\n",
    "    gene_splicing_scores = iso_variances.groupby(current_gene_map.values, sort=False).mean()\n",
    "    multi_iso_genes = adata.var_names[adata.var['filtered_n_isoforms'] > 1]\n",
    "    valid_genes = gene_splicing_scores.index.intersection(multi_iso_genes)\n",
    "    final_scores = gene_splicing_scores.loc[valid_genes]\n",
    "\n",
    "    if not final_scores.empty:\n",
    "        top_splicing_genes = final_scores.sort_values(ascending=False).head(n_top_splicing).index.tolist()\n",
    "        high_splice_genes = set(top_splicing_genes)\n",
    "    else:\n",
    "        high_splice_genes = set()\n",
    "        \n",
    "    print(f\"Identified {len(high_splice_genes)} genes with high splicing variance.\")\n",
    "    \n",
    "    final_genes_set = (hvg_genes | high_splice_genes)\n",
    "    final_genes = [gene for gene in adata.var_names if gene in final_genes_set]\n",
    "    adata = adata[:, final_genes].copy()\n",
    "\n",
    "    is_isoform_kept = current_gene_map.isin(final_genes_set)\n",
    "    final_iso_counts = filtered_iso_df.loc[:, is_isoform_kept]\n",
    "    final_iso_props  = new_props.loc[:, is_isoform_kept]\n",
    "    adata.obsm[isoform_key] = final_iso_counts\n",
    "    adata.obsm[proportion_key] = final_iso_props\n",
    "    \n",
    "    # 4. Run scVelo dynamical mode.\n",
    "    print(\"Preparing scVelo results:\")\n",
    "    adata.layers['raw_unspliced'] = adata.layers['unspliced'].copy()\n",
    "    adata.layers['raw_spliced'] = adata.layers['spliced'].copy()\n",
    "    if not normalized:\n",
    "        scv.pp.filter_and_normalize(adata, min_counts=0, min_cells=0, log=True)\n",
    "        scv.pp.moments(adata, n_pcs=30, n_neighbors=30)\n",
    "    else:\n",
    "        scv.pp.moments(adata, n_pcs=30, n_neighbors=30)\n",
    "    \n",
    "    scv.tl.recover_dynamics(adata, var_names='all', n_jobs=-1)\n",
    "    scv.tl.latent_time(adata)\n",
    "\n",
    "    n_total = adata.n_vars\n",
    "    n_fitted = adata.var['fit_alpha'].notnull().sum()\n",
    "    print(f\"Dynamics recovered for {n_fitted}/{n_total} genes.\")\n",
    "\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "540684ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 2000 × 1000\n",
      "    obs: 'cell_state', 'pseudotime'\n",
      "    var: 'gene_category', 'n_isoforms'\n",
      "    uns: 'proportions_ground_truth', 'proportions_observed', 'spliced_isoform_counts'\n",
      "    obsm: 'isoform_counts', 'proportion'\n",
      "    layers: 'alpha', 'beta', 'gamma', 'spliced', 'unspliced'\n",
      "Filtered cells from 2000 to 2000 (min_counts=10)\n",
      "Filtered isoforms from 3468 to 3468 based on isoform expression and global proportion.\n",
      "Found 800 expression HVGs.\n",
      "Identified 500 genes with high splicing variance.\n",
      "Preparing scVelo results:\n",
      "Normalized count data: X, spliced, unspliced.\n",
      "Logarithmized X.\n",
      "computing neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shizh\\.conda\\envs\\IsoVelo_test\\lib\\site-packages\\scvelo\\preprocessing\\utils.py:705: DeprecationWarning: `log1p` is deprecated since scVelo v0.3.0 and will be removed in a future version. Please use `log1p` from `scanpy.pp` instead.\n",
      "  log1p(adata)\n",
      "C:\\Users\\shizh\\AppData\\Local\\Temp\\ipykernel_37472\\3109797284.py:130: DeprecationWarning: Automatic neighbor calculation is deprecated since scvelo==0.4.0 and will be removed in a future version of scVelo. Please compute neighbors first with Scanpy.\n",
      "  scv.pp.moments(adata, n_pcs=30, n_neighbors=30)\n",
      "c:\\Users\\shizh\\.conda\\envs\\IsoVelo_test\\lib\\site-packages\\scvelo\\preprocessing\\moments.py:71: DeprecationWarning: `neighbors` is deprecated since scvelo==0.4.0 and will be removed in a future version of scVelo. Please compute neighbors with Scanpy.\n",
      "  neighbors(\n",
      "c:\\Users\\shizh\\.conda\\envs\\IsoVelo_test\\lib\\site-packages\\scvelo\\preprocessing\\neighbors.py:233: DeprecationWarning: Automatic computation of PCA is deprecated since scvelo==0.4.0 and will be removed in a future version of scVelo. Please compute PCA with Scanpy first.\n",
      "  _set_pca(adata=adata, n_pcs=n_pcs, use_highly_variable=use_highly_variable)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:00:00) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:00) --> added \n",
      "    'Ms' and 'Mu', moments of un/spliced abundances (adata.layers)\n",
      "recovering dynamics (using 32/32 cores)\n",
      "    finished (0:00:48) --> added \n",
      "    'fit_pars', fitted parameters for splicing dynamics (adata.var)\n",
      "computing velocities\n",
      "    finished (0:00:00) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n",
      "computing velocity graph (using 1/32 cores)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shizh\\.conda\\envs\\IsoVelo_test\\lib\\site-packages\\scvelo\\tools\\optimization.py:184: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  gamma[i] = np.linalg.pinv(A.T.dot(A)).dot(A.T.dot(y[:, i]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:00:00) --> added \n",
      "    'velocity_graph', sparse matrix with cosine correlations (adata.uns)\n",
      "computing terminal states\n",
      "    identified 5 regions of root cells and 1 region of end points .\n",
      "    finished (0:00:00) --> added\n",
      "    'root_cells', root cells of Markov diffusion process (adata.obs)\n",
      "    'end_points', end points of Markov diffusion process (adata.obs)\n",
      "computing latent time using root_cells as prior\n",
      "    finished (0:00:00) --> added \n",
      "    'latent_time', shared time (adata.obs)\n",
      "Dynamics recovered for 886/886 genes.\n"
     ]
    }
   ],
   "source": [
    "adata = anndata.read_h5ad('../../test_simulated_data_continuous_0.h5ad')\n",
    "print(adata)\n",
    "adata = preprocess_and_initialize_scvelo(\n",
    "    adata, \n",
    "    isoform_key=\"isoform_counts\", \n",
    "    proportion_key = \"proportion\",\n",
    "    min_isoform_counts=10, \n",
    "    min_cell_counts = 10,\n",
    "    min_isoform_prop=0.05, \n",
    "    n_top_genes=800,\n",
    "    n_top_splicing = 500,\n",
    "    min_cells_spanning = 10,\n",
    "    isoform_delimiter=\"_\",\n",
    "    normalized = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "08c9e1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 2000 × 886\n",
      "    obs: 'cell_state', 'pseudotime', 'n_counts', 'initial_size_unspliced', 'initial_size_spliced', 'initial_size', 'velocity_self_transition', 'root_cells', 'end_points', 'velocity_pseudotime', 'latent_time'\n",
      "    var: 'gene_category', 'n_isoforms', 'filtered_n_isoforms', 'fit_alpha', 'fit_beta', 'fit_gamma', 'fit_t_', 'fit_scaling', 'fit_std_u', 'fit_std_s', 'fit_likelihood', 'fit_u0', 'fit_s0', 'fit_pval_steady', 'fit_steady_u', 'fit_steady_s', 'fit_variance', 'fit_alignment_scaling', 'velocity_gamma', 'velocity_qreg_ratio', 'velocity_r2', 'velocity_genes'\n",
      "    uns: 'proportions_ground_truth', 'proportions_observed', 'spliced_isoform_counts', 'log1p', 'pca', 'neighbors', 'recover_dynamics', 'velocity_params', 'velocity_graph', 'velocity_graph_neg'\n",
      "    obsm: 'isoform_counts', 'proportion', 'X_pca'\n",
      "    varm: 'PCs', 'loss'\n",
      "    layers: 'alpha', 'beta', 'gamma', 'spliced', 'unspliced', 'raw_unspliced', 'raw_spliced', 'Ms', 'Mu', 'fit_t', 'fit_tau', 'fit_tau_', 'velocity', 'variance_velocity'\n",
      "    obsp: 'distances', 'connectivities'\n",
      "[[2 3 5 ... 2 1 2]\n",
      " [1 2 3 ... 2 4 2]\n",
      " [4 2 4 ... 0 3 2]\n",
      " ...\n",
      " [3 1 3 ... 1 1 1]\n",
      " [2 2 2 ... 4 2 2]\n",
      " [2 2 2 ... 5 6 7]]\n"
     ]
    }
   ],
   "source": [
    "print(adata)\n",
    "print(adata.layers['raw_unspliced'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3a63b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsoDataset(Dataset):\n",
    "    def __init__(self, adata):\n",
    "        # Get Unspliced counts (G genes)\n",
    "        U = adata.layers[\"raw_unspliced\"]\n",
    "        if sp.issparse(U):\n",
    "            U = U.toarray()\n",
    "        \n",
    "        # Get Isoform counts (I isoforms)\n",
    "        # Assume that adata.obsm[\"isoform_counts\"] includes spliced isoform count\n",
    "        I = adata.obsm[\"isoform_counts\"]\n",
    "        if hasattr(I, \"values\"): \n",
    "            I = I.values\n",
    "        if sp.issparse(I):        \n",
    "            I = I.toarray()\n",
    "            \n",
    "        # Merge: Cells x (Genes + Isoforms)\n",
    "        # Note: the input of the Encoder should be G + I\n",
    "        X = np.hstack([U, I]).astype(np.float32) \n",
    "        self.X = torch.from_numpy(X)\n",
    "        self.n_cells = self.X.shape[0]\n",
    "        self.n_genes = U.shape[1]\n",
    "        self.n_isoforms = I.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_cells\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the data and index\n",
    "        return self.X[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b8f14b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsoveloEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    Encodes U (unspliced) and Isoform counts into a latent cell embedding.\n",
    "    Inherits from scvi.nn.Encoder to leverage its VAE structure.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 input_dim:int, \n",
    "                 hidden_dim=32, \n",
    "                 latent_dim = 128, \n",
    "                 n_layers=2, \n",
    "                 dropout_rate=0.1, \n",
    "                 distribution=\"normal\", \n",
    "                 use_batch_norm=True, \n",
    "                 use_layer_norm=False,\n",
    "                 var_activation=nn.Softplus(),\n",
    "                 activation_fn=nn.ReLU,\n",
    "                 **kwargs):\n",
    "        super().__init__(n_input=input_dim, \n",
    "                         n_output=latent_dim,\n",
    "                         n_layers=n_layers,\n",
    "                         n_hidden=hidden_dim,\n",
    "                         dropout_rate=dropout_rate,\n",
    "                         distribution=distribution,\n",
    "                         use_batch_norm=use_batch_norm,\n",
    "                         use_layer_norm=use_layer_norm,\n",
    "                         var_activation=var_activation,\n",
    "                         activation_fn=activation_fn,\n",
    "                         **kwargs\n",
    "                         )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, *cat_list: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        :param x: Concatenated tensor of [U, Isoforms]\n",
    "        :return: A dictionary with 'qz_m', 'qz_v', 'z'\n",
    "        \"\"\"\n",
    "        # Encode x to get latent parameters\n",
    "        qz_m, qz_v, z = super().forward(x, *cat_list)\n",
    "        \n",
    "        return {\"qz_m\": qz_m, \"qz_v\": qz_v, \"z\": z}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d794e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder_from_adata(adata, **enc_kwargs):\n",
    "    U = adata.layers[\"raw_unspliced\"]\n",
    "    g = U.shape[1]\n",
    "    i = adata.obsm[\"isoform_counts\"].shape[1]\n",
    "    enc = IsoveloEncoder(input_dim=g + i, **enc_kwargs)\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4818e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0349a480",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsoveloDecoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_cells: int,\n",
    "                 n_genes: int,\n",
    "                 n_isoforms: int,\n",
    "                 latent_dim: int = 128,\n",
    "                 hidden_dim: int = 256,\n",
    "                 # Initialization values provided by scVelo\n",
    "                 init_time: np.ndarray = None,      # shape: (n_cells, )\n",
    "                 init_alpha: np.ndarray = None,     # shape: (n_genes, )\n",
    "                 init_beta_iso: np.ndarray = None,  # shape: (n_isoforms, ) <- (beta_gene * proportion)\n",
    "                 init_gamma: np.ndarray = None,     # shape: (n_isoforms, ) <- (gamma_gene * proportion)\n",
    "                 iso_to_gene: np.ndarray = None,    # shape: (n_isoforms, ) gene indices for each isoform\n",
    "                 device = torch.device):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        def inverse_softplus(x_np):\n",
    "            x_safe = np.maximum(x_np, 1e-6)\n",
    "            return np.log(np.exp(x_safe)-1)\n",
    "\n",
    "        self.n_genes = n_genes\n",
    "        self.n_isoforms = n_isoforms\n",
    "        self.device = device\n",
    "        if iso_to_gene is None:\n",
    "            raise ValueError(\"iso_to_gene mapping is required.\")\n",
    "        self.iso_to_gene = torch.from_numpy(iso_to_gene).long().to(self.device)\n",
    "\n",
    "        # --- A. Cell Time (t) ---\n",
    "        # independent parameters, not rely on z (cell * 1)\n",
    "        self.cell_time = nn.Parameter(torch.randn(n_cells, 1)) \n",
    "        if init_time is not None:\n",
    "            # Initialize with the scvelo output\n",
    "            self.cell_time.data.copy_(torch.from_numpy(init_time).float().unsqueeze(1))\n",
    "\n",
    "        # --- B. Gamma (γ) ---\n",
    "        # independent parameters, not rely on z (1 * isoform)\n",
    "        self.gamma = nn.Parameter(torch.ones(1, n_isoforms))\n",
    "        if init_gamma is not None:\n",
    "            # Initialize with the scvelo output\n",
    "            inv_gamma = inverse_softplus(init_gamma)\n",
    "            self.gamma.data.copy_(torch.from_numpy(inv_gamma).float().unsqueeze(0))\n",
    "\n",
    "        # --- C. Alpha Network (α) ---\n",
    "        # Input: z -> Output: Alpha (Cell * Gene)\n",
    "        self.alpha_fc1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.alpha_fc2 = nn.Linear(hidden_dim, n_genes) \n",
    "        \n",
    "        # Initialize the bias of the alpha\n",
    "        if init_alpha is not None:\n",
    "            # Initial weights should be small, the initial values should be determined mainly by the scvelo bias\n",
    "            nn.init.xavier_normal_(self.alpha_fc2.weight, gain=0.01)\n",
    "            # Set the bias to scvelo output (usually need to get log or inverse softplus, depending on the activation function)\n",
    "            # Assume that using Softplus activation. For simplicity, set to scvelo output, training will approximate these values\n",
    "            inv_alpha = inverse_softplus(init_alpha)\n",
    "            self.alpha_fc2.bias.data.copy_(torch.from_numpy(inv_alpha).float())\n",
    "\n",
    "        # --- D. Beta Network (β) ---\n",
    "        # Input: z -> Output: Beta (Cell * Isoform)\n",
    "        self.beta_fc1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.beta_fc2 = nn.Linear(hidden_dim, n_isoforms) \n",
    "        \n",
    "        # Initialize the bias of the beta\n",
    "        if init_beta_iso is not None:\n",
    "            nn.init.xavier_normal_(self.beta_fc2.weight, gain=0.01)\n",
    "            # Similar with alpha, here it should be isoform level beta\n",
    "            inv_beta = inverse_softplus(init_beta_iso)\n",
    "            self.beta_fc2.bias.data.copy_(torch.from_numpy(inv_beta).float())\n",
    "\n",
    "    def forward(self, z: torch.Tensor, cell_indices = None):\n",
    "        \"\"\"\n",
    "        z: [Batch, Latent_dim]\n",
    "        cell_indices: [Batch]\n",
    "        \"\"\"\n",
    "        # 1. Get cell time\n",
    "        if cell_indices is not None:\n",
    "            t = self.cell_time[cell_indices] # [Batch, 1]\n",
    "        else:\n",
    "            t = self.cell_time\n",
    "\n",
    "        # 2. Get alpha (non-negative)\n",
    "        h_alpha = F.relu(self.alpha_fc1(z))\n",
    "        alpha = F.softplus(self.alpha_fc2(h_alpha)) # [Batch, n_genes]\n",
    "\n",
    "        # 3. Get beta (non-negative)\n",
    "        h_beta = F.relu(self.beta_fc1(z))\n",
    "        beta = F.softplus(self.beta_fc2(h_beta))   # [Batch, n_isoforms]\n",
    "\n",
    "        # 4. Get gamma (non-negative)\n",
    "        gamma = F.softplus(self.gamma)             # [1, n_isoforms]\n",
    "\n",
    "        # Compute integrated u_hat and s_hat using analytical ODE solution\n",
    "        b_size = z.shape[0]\n",
    "\n",
    "        # Compute beta_total [b_size, n_genes]\n",
    "        beta_total = torch.zeros(b_size, self.n_genes, device=self.device)\n",
    "        beta_total.scatter_add_(1, self.iso_to_gene.unsqueeze(0).expand(b_size, -1), beta)\n",
    "        beta_total = torch.clamp(beta_total, min=1e-6)\n",
    "\n",
    "        # a_g [b_size, n_genes]\n",
    "        a_g = alpha / beta_total\n",
    "\n",
    "        # u_hat [b_size, n_genes]\n",
    "        exp_bt = torch.exp(-beta_total * t)\n",
    "        u_hat = a_g * (1 - exp_bt)\n",
    "\n",
    "        # s_hat [b_size, n_isoforms]\n",
    "        g_idx = self.iso_to_gene\n",
    "        a_expand = torch.index_select(a_g, 1, g_idx)  # [b_size, n_isoforms]\n",
    "        b_expand = torch.index_select(beta_total, 1, g_idx)  # [b_size, n_isoforms]\n",
    "        gamma_expand = gamma.expand(b_size, -1)  # [b_size, n_isoforms]\n",
    "        t_expand = t.expand(-1, self.n_isoforms)  # [b_size, n_isoforms]\n",
    "\n",
    "\n",
    "        denom = gamma_expand - b_expand\n",
    "        mask = torch.abs(denom) < 1e-6\n",
    "        s_hat = torch.zeros_like(beta)\n",
    "        non_mask = ~mask\n",
    "        s_hat[non_mask] = beta[non_mask] * a_expand[non_mask] * (\n",
    "            1.0 / gamma_expand[non_mask]\n",
    "            - torch.exp(-gamma_expand[non_mask] * t_expand[non_mask]) / gamma_expand[non_mask]\n",
    "            - torch.exp(-b_expand[non_mask] * t_expand[non_mask]) / denom[non_mask]\n",
    "            + torch.exp(-gamma_expand[non_mask] * t_expand[non_mask]) / denom[non_mask]\n",
    "        )\n",
    "        s_hat[mask] = beta[mask] * a_expand[mask] * (\n",
    "            (1.0 - torch.exp(-b_expand[mask] * t_expand[mask])) / b_expand[mask]\n",
    "            - t_expand[mask] * torch.exp(-b_expand[mask] * t_expand[mask])\n",
    "        )\n",
    "\n",
    "        #### Test\n",
    "        u_hat = torch.clamp(u_hat, min=0.0)\n",
    "        s_hat = torch.clamp(s_hat, min=0.0)\n",
    "        \n",
    "        return {\"cell_time\": t, \"gene_alpha\": alpha, \"isoform_beta\": beta, \"isoform_gamma\": gamma,\n",
    "                \"u_hat\": u_hat, \"s_hat\": s_hat}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "30fab0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 2000 × 886\n",
      "    obs: 'cell_state', 'pseudotime', 'n_counts', 'initial_size_unspliced', 'initial_size_spliced', 'initial_size', 'velocity_self_transition', 'root_cells', 'end_points', 'velocity_pseudotime', 'latent_time', 'isovelo_time'\n",
      "    var: 'gene_category', 'n_isoforms', 'filtered_n_isoforms', 'fit_alpha', 'fit_beta', 'fit_gamma', 'fit_t_', 'fit_scaling', 'fit_std_u', 'fit_std_s', 'fit_likelihood', 'fit_u0', 'fit_s0', 'fit_pval_steady', 'fit_steady_u', 'fit_steady_s', 'fit_variance', 'fit_alignment_scaling', 'velocity_gamma', 'velocity_qreg_ratio', 'velocity_r2', 'velocity_genes'\n",
      "    uns: 'proportions_ground_truth', 'proportions_observed', 'spliced_isoform_counts', 'log1p', 'pca', 'neighbors', 'recover_dynamics', 'velocity_params', 'velocity_graph', 'velocity_graph_neg', 'gamma'\n",
      "    obsm: 'isoform_counts', 'proportion', 'X_pca', 'X_isovelo', 'beta'\n",
      "    varm: 'PCs', 'loss'\n",
      "    layers: 'alpha', 'beta', 'gamma', 'spliced', 'unspliced', 'raw_unspliced', 'raw_spliced', 'Ms', 'Mu', 'fit_t', 'fit_tau', 'fit_tau_', 'velocity', 'variance_velocity'\n",
      "    obsp: 'distances', 'connectivities'\n"
     ]
    }
   ],
   "source": [
    "print(adata)\n",
    "def build_decoder_from_adata(adata, latent_dim=128, hidden_dim=256, device=torch.device):\n",
    "    n_cells = adata.n_obs\n",
    "    n_genes = adata.n_vars\n",
    "    n_isoforms = adata.obsm['isoform_counts'].shape[1]\n",
    "    # Get init_time\n",
    "    init_time = adata.obs['latent_time'].values if 'latent_time' in adata.obs else None\n",
    "    # Get init_alpha\n",
    "    init_alpha = adata.var['fit_alpha'].values if 'fit_alpha' in adata.var else None\n",
    "    # Get gene_map for isoforms\n",
    "    isoform_names = adata.obsm['isoform_counts'].columns if hasattr(adata.obsm['isoform_counts'], 'columns') else [str(i) for i in range(n_isoforms)]\n",
    "    isoform_delimiter = \"_\"\n",
    "    gene_names = [x.rsplit(isoform_delimiter, 1)[0] for x in isoform_names]\n",
    "    # gene_idx_for_iso\n",
    "    gene_to_idx = {g: i for i, g in enumerate(adata.var_names)}\n",
    "    iso_to_gene_idx = np.array([gene_to_idx[g] for g in gene_names])\n",
    "\n",
    "    adata.uns['iso_to_gene'] = iso_to_gene_idx\n",
    "\n",
    "    \n",
    "    # init_beta_iso, init_gamma\n",
    "    init_beta_iso = None\n",
    "    init_gamma_iso = None\n",
    "    if 'fit_beta' in adata.var and 'proportion' in adata.obsm:\n",
    "        mean_prop = np.nanmean(adata.obsm['proportion'], axis=0)\n",
    "        beta_gene = adata.var['fit_beta'].reindex(gene_names).values\n",
    "        gamma_gene = adata.var['fit_gamma'].reindex(gene_names).values\n",
    "        init_beta_iso = beta_gene * mean_prop\n",
    "        init_gamma_iso = gamma_gene * mean_prop\n",
    "    dec = IsoveloDecoder(n_cells, n_genes, n_isoforms, latent_dim, hidden_dim,\n",
    "                         init_time=init_time, init_alpha=init_alpha, init_beta_iso=init_beta_iso, init_gamma=init_gamma_iso,\n",
    "                         iso_to_gene=iso_to_gene_idx, device=device)\n",
    "    return dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "46e21616",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsoveloVAE(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def reparameterize(self, mu, var):\n",
    "        std = torch.sqrt(var + 1e-6)  # Add epsilon for stability\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x, cell_indices):\n",
    "        enc_out = self.encoder(x)\n",
    "        z_mu = enc_out['qz_m']\n",
    "        z_var = enc_out['qz_v']\n",
    "        z = self.reparameterize(z_mu, z_var)\n",
    "        dec_out = self.decoder(z, cell_indices)\n",
    "        return enc_out, dec_out, z_mu, z_var, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9e033ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, x, cell_indices, n_genes, kl_weight=1.0):\n",
    "    enc_out, dec_out, z_mu, z_var, z = model(x, cell_indices)\n",
    "    u_hat = dec_out['u_hat']\n",
    "    s_hat = dec_out['s_hat']\n",
    "    \n",
    "    # Observed data from x: first n_genes are unspliced, rest are isoform spliced\n",
    "    u_obs = x[:, :n_genes]\n",
    "    s_obs = x[:, n_genes:]\n",
    "    \n",
    "    # Reconstruction loss: Use Normal for continuous data\n",
    "    # Variance approximation: sqrt(mean + epsilon) for stability and Poisson-like behavior\n",
    "    # recon_loss_u = -Normal(u_hat, torch.sqrt(u_hat + 1e-6)).log_prob(u_obs).sum(dim=1).mean()\n",
    "    # recon_loss_s = -Normal(s_hat, torch.sqrt(s_hat + 1e-6)).log_prob(s_obs).sum(dim=1).mean()\n",
    "\n",
    "    ##### Try normal\n",
    "    recon_loss_u = -Normal(u_hat, torch.sqrt(u_hat + 1e-6)).log_prob(u_obs).sum(dim=1).mean()\n",
    "    recon_loss_s = -Normal(s_hat, torch.sqrt(s_hat + 1e-6)).log_prob(s_obs).sum(dim=1).mean()\n",
    "    \n",
    "    # KL divergence for latent z\n",
    "    kl_loss = kl_divergence(Normal(z_mu, torch.sqrt(z_var)), Normal(0, 1)).sum(dim=1).mean()\n",
    "    \n",
    "    total_loss = recon_loss_u + recon_loss_s + kl_weight * kl_loss\n",
    "    return total_loss, recon_loss_u, recon_loss_s, kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ba7a38de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_isovelo(adata, batch_size=128, epochs=100, lr=1e-3, kl_weight=1.0, device=torch.device('cpu')):\n",
    "    dataset = IsoDataset(adata)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    n_genes = dataset.n_genes\n",
    "    encoder = build_encoder_from_adata(adata, latent_dim=128, hidden_dim=32)\n",
    "    decoder = build_decoder_from_adata(adata, latent_dim=128, hidden_dim=256, device=device)\n",
    "    \n",
    "    model = IsoveloVAE(encoder, decoder).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_recon_u = 0\n",
    "        epoch_recon_s = 0\n",
    "        epoch_kl = 0\n",
    "        for batch in dataloader:\n",
    "            x, idx = batch\n",
    "            x = x.to(device)\n",
    "            idx = idx.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss, recon_u, recon_s, kl = compute_loss(model, x, idx, n_genes, kl_weight)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_recon_u += recon_u.item()\n",
    "            epoch_recon_s += recon_s.item()\n",
    "            epoch_kl += kl.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss / len(dataloader):.4f}, recon_u: {epoch_recon_u / len(dataloader):.4f}, recon_s: {epoch_recon_s / len(dataloader):.4f}, kl: {epoch_kl / len(dataloader):.4f}\")\n",
    "    \n",
    "    # After training, can extract latent z, times, etc.\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        full_dataloader = DataLoader(dataset, batch_size=adata.n_obs, shuffle=False)\n",
    "        x_full, idx_full = next(iter(full_dataloader))\n",
    "        x_full = x_full.to(device)\n",
    "        idx_full = idx_full.to(device)\n",
    "        enc_out, dec_out, z_mu, z_var, z = model(x_full, idx_full)\n",
    "        adata.obsm['X_isovelo'] = z.cpu().numpy()  # Latent representation\n",
    "        adata.obs['isovelo_time'] = dec_out['cell_time'].squeeze().cpu().numpy()\n",
    "        \n",
    "        # Extract predicted parameters\n",
    "        alpha = dec_out['gene_alpha'].cpu().numpy()  # cell x gene\n",
    "        beta = dec_out['isoform_beta'].cpu().numpy()  # cell x isoform\n",
    "        gamma = dec_out['isoform_gamma'].cpu().numpy()[0]  # isoform (global)\n",
    "        adata.layers['alpha'] = alpha\n",
    "        adata.obsm['beta'] = beta\n",
    "        adata.uns['gamma'] = gamma  # 1D array for isoforms\n",
    "        \n",
    "        # Compute RNA velocities using predicted params and observed u/s        \n",
    "        iso_to_gene = adata.uns['iso_to_gene']\n",
    "        n_cells = adata.n_obs\n",
    "        n_genes = adata.n_vars\n",
    "        n_isoforms = beta.shape[1]\n",
    "        \n",
    "        # Compute beta_total (cell x gene)\n",
    "        beta_total = np.zeros((n_cells, n_genes))\n",
    "        for i in range(n_isoforms):\n",
    "            g_idx = iso_to_gene[i]\n",
    "            beta_total[:, g_idx] += beta[:, i]\n",
    "        beta_total = np.maximum(beta_total, 1e-6)\n",
    "        \n",
    "        # Get observed u and s\n",
    "        u_obs = adata.layers['unspliced']\n",
    "        if sp.issparse(u_obs):\n",
    "            u_obs = u_obs.toarray()\n",
    "        s_obs = adata.obsm['isoform_counts']\n",
    "        if hasattr(s_obs, 'values'):\n",
    "            s_obs = s_obs.values\n",
    "        if sp.issparse(s_obs):\n",
    "            s_obs = s_obs.toarray()\n",
    "        \n",
    "        # Unspliced velocity (cell x gene)\n",
    "        velocity_u = alpha - beta_total * u_obs\n",
    "        adata.layers['velocity_u'] = velocity_u\n",
    "        \n",
    "        # Spliced velocity (cell x isoform)\n",
    "        velocity_s = np.zeros_like(beta)\n",
    "        for i in range(n_isoforms):\n",
    "            g_idx = iso_to_gene[i]\n",
    "            velocity_s[:, i] = beta[:, i] * u_obs[:, g_idx] - gamma[i] * s_obs[:, i]\n",
    "        adata.obsm['velocity_s'] = velocity_s\n",
    "        \n",
    "        # Aggregate spliced velocity to gene-level for scVelo compatibility\n",
    "        velocity_s_gene = np.zeros((n_cells, n_genes))\n",
    "        for i in range(n_isoforms):\n",
    "            g_idx = iso_to_gene[i]\n",
    "            velocity_s_gene[:, g_idx] += velocity_s[:, i]\n",
    "        adata.layers['velocity'] = velocity_s_gene  # Set for velocity_graph\n",
    "    \n",
    "    # Prepare embeddings and velocity graph for visualization\n",
    "    sc.pp.neighbors(adata, use_rep='X_isovelo', n_neighbors=30)\n",
    "    sc.tl.umap(adata)\n",
    "    scv.tl.velocity_graph(adata)\n",
    "    \n",
    "    return model, adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c4abecd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 118261016.8320, recon_u: 2450188.2787, recon_s: 115810804.4023, kl: 26.2121\n",
      "Epoch 2/200, Loss: 515307.0952, recon_u: 7834.1044, recon_s: 507435.3242, kl: 37.6700\n",
      "Epoch 3/200, Loss: 205649.7654, recon_u: 5831.3839, recon_s: 199778.7441, kl: 39.6351\n",
      "Epoch 4/200, Loss: 144782.8796, recon_u: 5336.6840, recon_s: 139404.6150, kl: 41.5808\n",
      "Epoch 5/200, Loss: 129654.1189, recon_u: 5187.4080, recon_s: 124424.1108, kl: 42.5997\n",
      "Epoch 6/200, Loss: 100478.6160, recon_u: 4949.3566, recon_s: 95484.9646, kl: 44.2944\n",
      "Epoch 7/200, Loss: 86507.1119, recon_u: 4822.4633, recon_s: 81639.1217, kl: 45.5264\n",
      "Epoch 8/200, Loss: 77739.5339, recon_u: 4732.3927, recon_s: 72960.8157, kl: 46.3260\n",
      "Epoch 9/200, Loss: 73463.5516, recon_u: 4713.4562, recon_s: 68701.8202, kl: 48.2760\n",
      "Epoch 10/200, Loss: 64881.8251, recon_u: 4615.9748, recon_s: 60215.9196, kl: 49.9316\n",
      "Epoch 11/200, Loss: 60449.9001, recon_u: 4579.5531, recon_s: 55818.6849, kl: 51.6623\n",
      "Epoch 12/200, Loss: 53404.9175, recon_u: 4494.7762, recon_s: 48856.4975, kl: 53.6438\n",
      "Epoch 13/200, Loss: 49058.4019, recon_u: 4455.4605, recon_s: 44547.7238, kl: 55.2174\n",
      "Epoch 14/200, Loss: 48779.0056, recon_u: 4379.8594, recon_s: 44342.7307, kl: 56.4155\n",
      "Epoch 15/200, Loss: 45826.9166, recon_u: 4359.2158, recon_s: 41409.2079, kl: 58.4927\n",
      "Epoch 16/200, Loss: 40707.8707, recon_u: 4308.6698, recon_s: 36338.7492, kl: 60.4513\n",
      "Epoch 17/200, Loss: 38947.4613, recon_u: 4272.9819, recon_s: 34613.1989, kl: 61.2805\n",
      "Epoch 18/200, Loss: 36645.8704, recon_u: 4272.0867, recon_s: 32311.1310, kl: 62.6524\n",
      "Epoch 19/200, Loss: 34595.8088, recon_u: 4189.9094, recon_s: 30341.3339, kl: 64.5657\n",
      "Epoch 20/200, Loss: 32918.2355, recon_u: 4169.4738, recon_s: 28683.3501, kl: 65.4121\n",
      "Epoch 21/200, Loss: 34076.2871, recon_u: 4158.4945, recon_s: 29851.1395, kl: 66.6533\n",
      "Epoch 22/200, Loss: 30602.7866, recon_u: 4116.1788, recon_s: 26418.3418, kl: 68.2660\n",
      "Epoch 23/200, Loss: 31310.0403, recon_u: 4121.6519, recon_s: 27118.8571, kl: 69.5310\n",
      "Epoch 24/200, Loss: 28841.5946, recon_u: 4054.3265, recon_s: 24716.2055, kl: 71.0627\n",
      "Epoch 25/200, Loss: 29218.5744, recon_u: 4032.4839, recon_s: 25114.2105, kl: 71.8800\n",
      "Epoch 26/200, Loss: 26885.4046, recon_u: 3975.7698, recon_s: 22835.4901, kl: 74.1447\n",
      "Epoch 27/200, Loss: 26615.2643, recon_u: 3945.7762, recon_s: 22594.9849, kl: 74.5031\n",
      "Epoch 28/200, Loss: 27677.0339, recon_u: 3908.8786, recon_s: 23692.0889, kl: 76.0664\n",
      "Epoch 29/200, Loss: 25480.0230, recon_u: 3904.8183, recon_s: 21498.2408, kl: 76.9638\n",
      "Epoch 30/200, Loss: 24607.8510, recon_u: 3863.2096, recon_s: 20665.6997, kl: 78.9415\n",
      "Epoch 31/200, Loss: 23372.0357, recon_u: 3806.5328, recon_s: 19485.5657, kl: 79.9371\n",
      "Epoch 32/200, Loss: 23085.8477, recon_u: 3773.9680, recon_s: 19231.1825, kl: 80.6970\n",
      "Epoch 33/200, Loss: 21971.0925, recon_u: 3731.0718, recon_s: 18157.2264, kl: 82.7943\n",
      "Epoch 34/200, Loss: 22083.2719, recon_u: 3706.5117, recon_s: 18292.5419, kl: 84.2184\n",
      "Epoch 35/200, Loss: 21348.1770, recon_u: 3678.0479, recon_s: 17584.5255, kl: 85.6037\n",
      "Epoch 36/200, Loss: 21071.3095, recon_u: 3641.9301, recon_s: 17343.1395, kl: 86.2400\n",
      "Epoch 37/200, Loss: 20100.5291, recon_u: 3568.7214, recon_s: 16444.0289, kl: 87.7787\n",
      "Epoch 38/200, Loss: 20327.0602, recon_u: 3558.5709, recon_s: 16679.3445, kl: 89.1446\n",
      "Epoch 39/200, Loss: 19095.0371, recon_u: 3510.6115, recon_s: 15493.6664, kl: 90.7590\n",
      "Epoch 40/200, Loss: 19573.6118, recon_u: 3498.4913, recon_s: 15984.4469, kl: 90.6735\n",
      "Epoch 41/200, Loss: 18643.6821, recon_u: 3450.1509, recon_s: 15100.8827, kl: 92.6485\n",
      "Epoch 42/200, Loss: 17900.1748, recon_u: 3404.9233, recon_s: 14400.8513, kl: 94.4002\n",
      "Epoch 43/200, Loss: 17645.5421, recon_u: 3385.9741, recon_s: 14162.7558, kl: 96.8121\n",
      "Epoch 44/200, Loss: 16925.9995, recon_u: 3328.4483, recon_s: 13501.3587, kl: 96.1926\n",
      "Epoch 45/200, Loss: 16590.7016, recon_u: 3300.4613, recon_s: 13192.4202, kl: 97.8202\n",
      "Epoch 46/200, Loss: 17306.1049, recon_u: 3282.4215, recon_s: 13925.2990, kl: 98.3843\n",
      "Epoch 47/200, Loss: 16858.9564, recon_u: 3256.9414, recon_s: 13501.9223, kl: 100.0928\n",
      "Epoch 48/200, Loss: 16392.9900, recon_u: 3232.6068, recon_s: 13059.4159, kl: 100.9671\n",
      "Epoch 49/200, Loss: 15804.2125, recon_u: 3181.0880, recon_s: 12518.0104, kl: 105.1144\n",
      "Epoch 50/200, Loss: 15689.3236, recon_u: 3158.0917, recon_s: 12427.6382, kl: 103.5936\n",
      "Epoch 51/200, Loss: 15546.7902, recon_u: 3122.8164, recon_s: 12318.0008, kl: 105.9728\n",
      "Epoch 52/200, Loss: 14882.9582, recon_u: 3116.3752, recon_s: 11659.4200, kl: 107.1631\n",
      "Epoch 53/200, Loss: 14870.8130, recon_u: 3066.7266, recon_s: 11696.5835, kl: 107.5029\n",
      "Epoch 54/200, Loss: 14864.5186, recon_u: 3049.3929, recon_s: 11707.1925, kl: 107.9331\n",
      "Epoch 55/200, Loss: 14553.7150, recon_u: 3037.1694, recon_s: 11406.2432, kl: 110.3023\n",
      "Epoch 56/200, Loss: 14119.1277, recon_u: 2998.9690, recon_s: 11008.9448, kl: 111.2138\n",
      "Epoch 57/200, Loss: 14399.6569, recon_u: 2971.1818, recon_s: 11317.5191, kl: 110.9560\n",
      "Epoch 58/200, Loss: 13623.2153, recon_u: 2927.5732, recon_s: 10581.6455, kl: 113.9966\n",
      "Epoch 59/200, Loss: 13951.3787, recon_u: 2929.4905, recon_s: 10907.2887, kl: 114.5994\n",
      "Epoch 60/200, Loss: 14150.4799, recon_u: 2903.7872, recon_s: 11132.4680, kl: 114.2248\n",
      "Epoch 61/200, Loss: 13235.7018, recon_u: 2877.7804, recon_s: 10241.6254, kl: 116.2961\n",
      "Epoch 62/200, Loss: 13420.8514, recon_u: 2861.3637, recon_s: 10442.0455, kl: 117.4421\n",
      "Epoch 63/200, Loss: 13181.7675, recon_u: 2827.0141, recon_s: 10234.8976, kl: 119.8560\n",
      "Epoch 64/200, Loss: 12875.7119, recon_u: 2802.0282, recon_s: 9954.0237, kl: 119.6599\n",
      "Epoch 65/200, Loss: 12989.5853, recon_u: 2778.8225, recon_s: 10090.1046, kl: 120.6582\n",
      "Epoch 66/200, Loss: 12823.4647, recon_u: 2746.3944, recon_s: 9954.6063, kl: 122.4641\n",
      "Epoch 67/200, Loss: 12410.1274, recon_u: 2745.3035, recon_s: 9541.5413, kl: 123.2827\n",
      "Epoch 68/200, Loss: 12522.2884, recon_u: 2715.5856, recon_s: 9683.3362, kl: 123.3667\n",
      "Epoch 69/200, Loss: 12252.4065, recon_u: 2700.2972, recon_s: 9426.1548, kl: 125.9544\n",
      "Epoch 70/200, Loss: 12459.3360, recon_u: 2679.8170, recon_s: 9654.3352, kl: 125.1839\n",
      "Epoch 71/200, Loss: 11983.0230, recon_u: 2662.5999, recon_s: 9191.0590, kl: 129.3641\n",
      "Epoch 72/200, Loss: 12193.5838, recon_u: 2647.0886, recon_s: 9416.5755, kl: 129.9196\n",
      "Epoch 73/200, Loss: 12424.6510, recon_u: 2634.1317, recon_s: 9661.6386, kl: 128.8806\n",
      "Epoch 74/200, Loss: 12127.8641, recon_u: 2603.5110, recon_s: 9390.6721, kl: 133.6809\n",
      "Epoch 75/200, Loss: 11571.4910, recon_u: 2572.7583, recon_s: 8866.4132, kl: 132.3195\n",
      "Epoch 76/200, Loss: 11666.4814, recon_u: 2559.0558, recon_s: 8973.6470, kl: 133.7784\n",
      "Epoch 77/200, Loss: 11933.8405, recon_u: 2554.9662, recon_s: 9244.8191, kl: 134.0552\n",
      "Epoch 78/200, Loss: 11419.2996, recon_u: 2541.0765, recon_s: 8744.5078, kl: 133.7152\n",
      "Epoch 79/200, Loss: 11141.0029, recon_u: 2517.3341, recon_s: 8486.3920, kl: 137.2768\n",
      "Epoch 80/200, Loss: 11173.9539, recon_u: 2500.1189, recon_s: 8537.4279, kl: 136.4071\n",
      "Epoch 81/200, Loss: 11622.7791, recon_u: 2481.1740, recon_s: 9002.3080, kl: 139.2971\n",
      "Epoch 82/200, Loss: 10896.3233, recon_u: 2472.1460, recon_s: 8283.5064, kl: 140.6708\n",
      "Epoch 83/200, Loss: 10995.6562, recon_u: 2455.0783, recon_s: 8399.2859, kl: 141.2919\n",
      "Epoch 84/200, Loss: 11010.4645, recon_u: 2442.3788, recon_s: 8426.7564, kl: 141.3294\n",
      "Epoch 85/200, Loss: 10843.2018, recon_u: 2437.2025, recon_s: 8263.9465, kl: 142.0528\n",
      "Epoch 86/200, Loss: 10742.3423, recon_u: 2424.1021, recon_s: 8172.4015, kl: 145.8387\n",
      "Epoch 87/200, Loss: 10737.1341, recon_u: 2406.6311, recon_s: 8186.2548, kl: 144.2481\n",
      "Epoch 88/200, Loss: 10935.1122, recon_u: 2396.9969, recon_s: 8390.6500, kl: 147.4654\n",
      "Epoch 89/200, Loss: 10656.1126, recon_u: 2372.6027, recon_s: 8134.9626, kl: 148.5472\n",
      "Epoch 90/200, Loss: 10857.9397, recon_u: 2379.0633, recon_s: 8331.5630, kl: 147.3135\n",
      "Epoch 91/200, Loss: 10223.9824, recon_u: 2346.0494, recon_s: 7726.9676, kl: 150.9654\n",
      "Epoch 92/200, Loss: 10316.0072, recon_u: 2337.5029, recon_s: 7826.8586, kl: 151.6458\n",
      "Epoch 93/200, Loss: 10488.1055, recon_u: 2329.5606, recon_s: 8004.0076, kl: 154.5373\n",
      "Epoch 94/200, Loss: 10106.8356, recon_u: 2314.8662, recon_s: 7635.8994, kl: 156.0701\n",
      "Epoch 95/200, Loss: 10437.9448, recon_u: 2311.8614, recon_s: 7972.0459, kl: 154.0377\n",
      "Epoch 96/200, Loss: 10157.3110, recon_u: 2303.7851, recon_s: 7700.1279, kl: 153.3981\n",
      "Epoch 97/200, Loss: 10088.6619, recon_u: 2285.3353, recon_s: 7647.2443, kl: 156.0822\n",
      "Epoch 98/200, Loss: 10710.6075, recon_u: 2288.9257, recon_s: 8264.3110, kl: 157.3707\n",
      "Epoch 99/200, Loss: 10306.9942, recon_u: 2278.0561, recon_s: 7870.0181, kl: 158.9201\n",
      "Epoch 100/200, Loss: 9972.8174, recon_u: 2269.6821, recon_s: 7544.2668, kl: 158.8685\n",
      "Epoch 101/200, Loss: 9987.8517, recon_u: 2258.2048, recon_s: 7569.6235, kl: 160.0235\n",
      "Epoch 102/200, Loss: 10022.8071, recon_u: 2244.3085, recon_s: 7619.1622, kl: 159.3365\n",
      "Epoch 103/200, Loss: 9943.7578, recon_u: 2239.3613, recon_s: 7539.0091, kl: 165.3873\n",
      "Epoch 104/200, Loss: 9924.1805, recon_u: 2227.5337, recon_s: 7531.3428, kl: 165.3040\n",
      "Epoch 105/200, Loss: 9749.2025, recon_u: 2220.3101, recon_s: 7361.7808, kl: 167.1115\n",
      "Epoch 106/200, Loss: 9735.4306, recon_u: 2212.9434, recon_s: 7356.6883, kl: 165.7990\n",
      "Epoch 107/200, Loss: 9784.3207, recon_u: 2203.2347, recon_s: 7414.5889, kl: 166.4971\n",
      "Epoch 108/200, Loss: 10305.5288, recon_u: 2209.9209, recon_s: 7927.9383, kl: 167.6697\n",
      "Epoch 109/200, Loss: 9740.0040, recon_u: 2195.0716, recon_s: 7376.4066, kl: 168.5260\n",
      "Epoch 110/200, Loss: 9624.8126, recon_u: 2183.8054, recon_s: 7269.6520, kl: 171.3552\n",
      "Epoch 111/200, Loss: 9535.0323, recon_u: 2178.8909, recon_s: 7183.7311, kl: 172.4103\n",
      "Epoch 112/200, Loss: 9643.7104, recon_u: 2173.5072, recon_s: 7295.9825, kl: 174.2207\n",
      "Epoch 113/200, Loss: 9547.4150, recon_u: 2165.3996, recon_s: 7208.5683, kl: 173.4471\n",
      "Epoch 114/200, Loss: 9586.0456, recon_u: 2160.9363, recon_s: 7250.9527, kl: 174.1567\n",
      "Epoch 115/200, Loss: 9597.4826, recon_u: 2151.1015, recon_s: 7272.1180, kl: 174.2632\n",
      "Epoch 116/200, Loss: 9324.6230, recon_u: 2143.2990, recon_s: 7003.0047, kl: 178.3193\n",
      "Epoch 117/200, Loss: 9519.1661, recon_u: 2139.4606, recon_s: 7202.6658, kl: 177.0396\n",
      "Epoch 118/200, Loss: 9552.1441, recon_u: 2127.9967, recon_s: 7246.4376, kl: 177.7100\n",
      "Epoch 119/200, Loss: 9283.1554, recon_u: 2124.0032, recon_s: 6976.7435, kl: 182.4089\n",
      "Epoch 120/200, Loss: 9282.3727, recon_u: 2121.1081, recon_s: 6978.4585, kl: 182.8060\n",
      "Epoch 121/200, Loss: 9393.3398, recon_u: 2115.7971, recon_s: 7097.7167, kl: 179.8260\n",
      "Epoch 122/200, Loss: 9283.7881, recon_u: 2106.6608, recon_s: 6995.8608, kl: 181.2665\n",
      "Epoch 123/200, Loss: 9100.1375, recon_u: 2098.5554, recon_s: 6813.5788, kl: 188.0034\n",
      "Epoch 124/200, Loss: 9219.4470, recon_u: 2096.3211, recon_s: 6938.2721, kl: 184.8537\n",
      "Epoch 125/200, Loss: 9179.8357, recon_u: 2090.3319, recon_s: 6902.0858, kl: 187.4180\n",
      "Epoch 126/200, Loss: 9056.3075, recon_u: 2082.1591, recon_s: 6785.7279, kl: 188.4206\n",
      "Epoch 127/200, Loss: 9107.7776, recon_u: 2077.7094, recon_s: 6841.1118, kl: 188.9564\n",
      "Epoch 128/200, Loss: 9267.6532, recon_u: 2074.6156, recon_s: 7003.9296, kl: 189.1078\n",
      "Epoch 129/200, Loss: 9064.4638, recon_u: 2072.4628, recon_s: 6799.8130, kl: 192.1880\n",
      "Epoch 130/200, Loss: 8991.1217, recon_u: 2067.9867, recon_s: 6730.2585, kl: 192.8766\n",
      "Epoch 131/200, Loss: 8941.8869, recon_u: 2058.6057, recon_s: 6688.0289, kl: 195.2523\n",
      "Epoch 132/200, Loss: 9230.1772, recon_u: 2059.0279, recon_s: 6977.4309, kl: 193.7184\n",
      "Epoch 133/200, Loss: 8998.1258, recon_u: 2055.3623, recon_s: 6746.8098, kl: 195.9537\n",
      "Epoch 134/200, Loss: 8880.2107, recon_u: 2043.1051, recon_s: 6638.4967, kl: 198.6089\n",
      "Epoch 135/200, Loss: 8939.4507, recon_u: 2047.2422, recon_s: 6697.0372, kl: 195.1712\n",
      "Epoch 136/200, Loss: 8866.0715, recon_u: 2038.7914, recon_s: 6627.9075, kl: 199.3726\n",
      "Epoch 137/200, Loss: 8801.2308, recon_u: 2034.8442, recon_s: 6567.1282, kl: 199.2583\n",
      "Epoch 138/200, Loss: 8679.5573, recon_u: 2020.9859, recon_s: 6455.2004, kl: 203.3709\n",
      "Epoch 139/200, Loss: 9051.8321, recon_u: 2026.6321, recon_s: 6823.9538, kl: 201.2461\n",
      "Epoch 140/200, Loss: 8910.8641, recon_u: 2022.5165, recon_s: 6684.6492, kl: 203.6985\n",
      "Epoch 141/200, Loss: 8663.6222, recon_u: 2016.6384, recon_s: 6442.5925, kl: 204.3914\n",
      "Epoch 142/200, Loss: 8786.8219, recon_u: 2013.6351, recon_s: 6564.5727, kl: 208.6141\n",
      "Epoch 143/200, Loss: 8643.9229, recon_u: 2003.3650, recon_s: 6431.6471, kl: 208.9108\n",
      "Epoch 144/200, Loss: 8793.8640, recon_u: 2004.8501, recon_s: 6581.8598, kl: 207.1541\n",
      "Epoch 145/200, Loss: 8723.0228, recon_u: 2005.7286, recon_s: 6506.2682, kl: 211.0259\n",
      "Epoch 146/200, Loss: 8637.1061, recon_u: 1995.9821, recon_s: 6433.2177, kl: 207.9062\n",
      "Epoch 147/200, Loss: 8632.6935, recon_u: 1992.2132, recon_s: 6430.4454, kl: 210.0349\n",
      "Epoch 148/200, Loss: 8638.8135, recon_u: 1987.0328, recon_s: 6440.3460, kl: 211.4347\n",
      "Epoch 149/200, Loss: 8768.0615, recon_u: 1988.1680, recon_s: 6567.4732, kl: 212.4203\n",
      "Epoch 150/200, Loss: 8717.0439, recon_u: 1990.4404, recon_s: 6515.6549, kl: 210.9485\n",
      "Epoch 151/200, Loss: 8646.5783, recon_u: 1975.5498, recon_s: 6455.1196, kl: 215.9088\n",
      "Epoch 152/200, Loss: 8700.0460, recon_u: 1983.2809, recon_s: 6504.7720, kl: 211.9931\n",
      "Epoch 153/200, Loss: 8565.3846, recon_u: 1973.1234, recon_s: 6374.6609, kl: 217.6003\n",
      "Epoch 154/200, Loss: 8685.0061, recon_u: 1967.7971, recon_s: 6494.5342, kl: 222.6749\n",
      "Epoch 155/200, Loss: 8534.5267, recon_u: 1967.5640, recon_s: 6349.5211, kl: 217.4415\n",
      "Epoch 156/200, Loss: 8491.0316, recon_u: 1960.3607, recon_s: 6312.4742, kl: 218.1967\n",
      "Epoch 157/200, Loss: 8509.1862, recon_u: 1962.5039, recon_s: 6325.3273, kl: 221.3550\n",
      "Epoch 158/200, Loss: 8442.9155, recon_u: 1957.1368, recon_s: 6261.8507, kl: 223.9279\n",
      "Epoch 159/200, Loss: 8386.5070, recon_u: 1950.9367, recon_s: 6209.5595, kl: 226.0108\n",
      "Epoch 160/200, Loss: 8386.9974, recon_u: 1951.5449, recon_s: 6209.8651, kl: 225.5874\n",
      "Epoch 161/200, Loss: 8446.1779, recon_u: 1948.2879, recon_s: 6268.6448, kl: 229.2452\n",
      "Epoch 162/200, Loss: 8592.5078, recon_u: 1945.7615, recon_s: 6419.8736, kl: 226.8726\n",
      "Epoch 163/200, Loss: 8390.4428, recon_u: 1938.2815, recon_s: 6218.8817, kl: 233.2797\n",
      "Epoch 164/200, Loss: 8262.5361, recon_u: 1933.4968, recon_s: 6094.6975, kl: 234.3419\n",
      "Epoch 165/200, Loss: 8271.0778, recon_u: 1928.4720, recon_s: 6106.6293, kl: 235.9766\n",
      "Epoch 166/200, Loss: 8375.6136, recon_u: 1931.8220, recon_s: 6205.9009, kl: 237.8907\n",
      "Epoch 167/200, Loss: 8294.8042, recon_u: 1929.2336, recon_s: 6134.2232, kl: 231.3475\n",
      "Epoch 168/200, Loss: 8745.7819, recon_u: 1937.5017, recon_s: 6572.1153, kl: 236.1649\n",
      "Epoch 169/200, Loss: 8422.2241, recon_u: 1924.3688, recon_s: 6263.1423, kl: 234.7129\n",
      "Epoch 170/200, Loss: 8198.8769, recon_u: 1910.9123, recon_s: 6047.8531, kl: 240.1115\n",
      "Epoch 171/200, Loss: 8147.2181, recon_u: 1913.9148, recon_s: 5995.8760, kl: 237.4274\n",
      "Epoch 172/200, Loss: 8223.9245, recon_u: 1911.1068, recon_s: 6075.1402, kl: 237.6776\n",
      "Epoch 173/200, Loss: 8225.6000, recon_u: 1907.5457, recon_s: 6080.0851, kl: 237.9692\n",
      "Epoch 174/200, Loss: 8175.6932, recon_u: 1908.4724, recon_s: 6026.6217, kl: 240.5991\n",
      "Epoch 175/200, Loss: 8126.3806, recon_u: 1906.5879, recon_s: 5979.7517, kl: 240.0409\n",
      "Epoch 176/200, Loss: 8213.9594, recon_u: 1902.8982, recon_s: 6065.2786, kl: 245.7826\n",
      "Epoch 177/200, Loss: 8205.2087, recon_u: 1894.4573, recon_s: 6064.0210, kl: 246.7306\n",
      "Epoch 178/200, Loss: 8075.7792, recon_u: 1894.4776, recon_s: 5933.4015, kl: 247.9001\n",
      "Epoch 179/200, Loss: 8135.6700, recon_u: 1893.9699, recon_s: 5998.4108, kl: 243.2894\n",
      "Epoch 180/200, Loss: 8058.1219, recon_u: 1889.9462, recon_s: 5919.0936, kl: 249.0822\n",
      "Epoch 181/200, Loss: 8049.4136, recon_u: 1885.7906, recon_s: 5912.4283, kl: 251.1947\n",
      "Epoch 182/200, Loss: 7926.6739, recon_u: 1882.8060, recon_s: 5788.5797, kl: 255.2883\n",
      "Epoch 183/200, Loss: 8002.2380, recon_u: 1882.3903, recon_s: 5863.5541, kl: 256.2936\n",
      "Epoch 184/200, Loss: 8004.9933, recon_u: 1877.2416, recon_s: 5876.5751, kl: 251.1767\n",
      "Epoch 185/200, Loss: 7909.9723, recon_u: 1877.6515, recon_s: 5781.0387, kl: 251.2821\n",
      "Epoch 186/200, Loss: 8018.6206, recon_u: 1874.1388, recon_s: 5890.3338, kl: 254.1480\n",
      "Epoch 187/200, Loss: 7987.3739, recon_u: 1873.5841, recon_s: 5858.1191, kl: 255.6708\n",
      "Epoch 188/200, Loss: 7827.7119, recon_u: 1868.5041, recon_s: 5706.4570, kl: 252.7509\n",
      "Epoch 189/200, Loss: 7874.1246, recon_u: 1867.4194, recon_s: 5751.9190, kl: 254.7861\n",
      "Epoch 190/200, Loss: 7899.1927, recon_u: 1863.9877, recon_s: 5777.3390, kl: 257.8662\n",
      "Epoch 191/200, Loss: 7889.5893, recon_u: 1862.0395, recon_s: 5767.8332, kl: 259.7167\n",
      "Epoch 192/200, Loss: 7739.9401, recon_u: 1857.8713, recon_s: 5622.1212, kl: 259.9476\n",
      "Epoch 193/200, Loss: 7765.7192, recon_u: 1855.0958, recon_s: 5651.5639, kl: 259.0595\n",
      "Epoch 194/200, Loss: 7965.6477, recon_u: 1860.6553, recon_s: 5845.6187, kl: 259.3738\n",
      "Epoch 195/200, Loss: 7800.8605, recon_u: 1853.2424, recon_s: 5687.9717, kl: 259.6464\n",
      "Epoch 196/200, Loss: 7747.7214, recon_u: 1850.3738, recon_s: 5632.4901, kl: 264.8573\n",
      "Epoch 197/200, Loss: 7841.0956, recon_u: 1852.5344, recon_s: 5727.6461, kl: 260.9151\n",
      "Epoch 198/200, Loss: 8008.1089, recon_u: 1852.2149, recon_s: 5891.2274, kl: 264.6666\n",
      "Epoch 199/200, Loss: 7991.3394, recon_u: 1850.5794, recon_s: 5876.1793, kl: 264.5807\n",
      "Epoch 200/200, Loss: 7911.3010, recon_u: 1847.1279, recon_s: 5794.8689, kl: 269.3041\n",
      "computing velocity graph (using 1/32 cores)\n",
      "    finished (0:00:00) --> added \n",
      "    'velocity_graph', sparse matrix with cosine correlations (adata.uns)\n"
     ]
    }
   ],
   "source": [
    "model, trained_adata = train_isovelo(adata, batch_size=64, epochs=200, lr=0.001, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "079dd264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scv.pl.velocity_graph(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a4d1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1cfc418",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c69369c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class IsoveloDecoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 n_cells: int, \n",
    "                 n_genes: int, \n",
    "                 n_isoforms: int, \n",
    "                 g2i_mask: torch.Tensor, \n",
    "                 latent_dim: int = 128, \n",
    "                 hidden_dim: int = 256,\n",
    "                 n_steps: int = 10,  # 把时间切成10份来积分\n",
    "                 init_time: np.ndarray = None,       \n",
    "                 init_alpha: np.ndarray = None,      \n",
    "                 init_beta_iso: np.ndarray = None,   \n",
    "                 init_gamma: np.ndarray = None,      \n",
    "                 device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.n_genes = n_genes\n",
    "        self.n_isoforms = n_isoforms\n",
    "        self.n_steps = n_steps # 积分步数\n",
    "        self.device = device\n",
    "        \n",
    "        self.register_buffer('g2i_mask', g2i_mask.float().to(device)) \n",
    "\n",
    "        # --- Parameters ---\n",
    "        # 1. Cell Time (每个细胞独立的时间)\n",
    "        if init_time is not None:\n",
    "            t_init = torch.from_numpy(init_time).float().view(-1, 1)\n",
    "        else:\n",
    "            t_init = torch.rand(n_cells, 1) * 5.0\n",
    "        self.cell_time_param = nn.Parameter(t_init)\n",
    "\n",
    "        # 2. Gamma (常数)\n",
    "        self.gamma_param = nn.Parameter(torch.zeros(1, n_isoforms))\n",
    "        if init_gamma is not None:\n",
    "            self.gamma_param.data.copy_(self._inverse_softplus(torch.from_numpy(init_gamma).float().unsqueeze(0)))\n",
    "\n",
    "        # 3. Networks for Alpha/Beta (z -> parameter)\n",
    "        self.alpha_fc = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim), nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, n_genes)\n",
    "        )\n",
    "        self.beta_fc = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim), nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, n_isoforms)\n",
    "        )\n",
    "        \n",
    "        # Initialization logic (omitted for brevity, same as before)\n",
    "        if init_alpha is not None:\n",
    "            inv_alpha = self._inverse_softplus(torch.from_numpy(init_alpha).float())\n",
    "            self.alpha_fc[-1].bias.data.copy_(inv_alpha)\n",
    "        if init_beta_iso is not None:\n",
    "            inv_beta = self._inverse_softplus(torch.from_numpy(init_beta_iso).float())\n",
    "            self.beta_fc[-1].bias.data.copy_(inv_beta)\n",
    "\n",
    "    @staticmethod\n",
    "    def _inverse_softplus(x):\n",
    "        return torch.log(torch.exp(x) - 1.0 + 1e-6)\n",
    "\n",
    "    def forward(self, z_final, cell_indices):\n",
    "        \"\"\"\n",
    "        z_final: [Batch, Latent] 细胞当前的潜在状态\n",
    "        cell_indices: [Batch] 用于取时间\n",
    "        \"\"\"\n",
    "        batch_size = z_final.shape[0]\n",
    "        \n",
    "        # 1. 获取这个 Batch 中每个细胞的总时间 T\n",
    "        T = F.softplus(self.cell_time_param[cell_indices]) # [Batch, 1]\n",
    "        \n",
    "        # 2. 构造虚拟历史 (Virtual History)\n",
    "        # 我们假设细胞是从 z=0 演化到 z=z_final 的\n",
    "        # 我们生成 n_steps 个时间点，代表 0% T, 10% T, ... 90% T\n",
    "        \n",
    "        # 生成插值系数: [0, 0.1, 0.2, ..., 0.9] (假设 n_steps=10)\n",
    "        steps_ratio = torch.linspace(0, 1 - 1/self.n_steps, self.n_steps, device=self.device)\n",
    "        \n",
    "        # 扩展 z: [Batch, Steps, Latent]\n",
    "        # z_history[b, s, :] = z_final[b, :] * steps_ratio[s]\n",
    "        # 这就模拟了细胞从不成熟(0)到成熟(z_final)的过程\n",
    "        z_history = torch.einsum('bl,s->bsl', z_final, steps_ratio)\n",
    "        \n",
    "        # 3. 并行计算历史时刻的 Alpha 和 Beta\n",
    "        # 输入维度: [Batch * Steps, Latent] -> 输出: [Batch * Steps, Genes]\n",
    "        # 这样 alpha 就随状态(也就是随时间)变化了！\n",
    "        flat_z = z_history.reshape(-1, z_final.shape[1])\n",
    "        \n",
    "        alpha_flat = F.softplus(self.alpha_fc(flat_z))\n",
    "        beta_iso_flat = F.softplus(self.beta_fc(flat_z))\n",
    "        \n",
    "        # Reshape 回 [Batch, Steps, Features]\n",
    "        alpha_seq = alpha_flat.reshape(batch_size, self.n_steps, self.n_genes)\n",
    "        beta_iso_seq = beta_iso_flat.reshape(batch_size, self.n_steps, self.n_isoforms)\n",
    "        \n",
    "        # 计算 Gene level beta\n",
    "        beta_gene_seq = torch.einsum('bsi,gi->bsg', beta_iso_seq, self.g2i_mask)\n",
    "        \n",
    "        # 获取 Gamma (constant)\n",
    "        gamma = F.softplus(self.gamma_param)\n",
    "        \n",
    "        # 4. 数值积分 (Euler Method, 最简单直观的 delta time 累加)\n",
    "        # 类似于你说的 delta time * alpha\n",
    "        \n",
    "        dt = T / self.n_steps # [Batch, 1] 每个 step 的时长\n",
    "        \n",
    "        # 初始化 u, s 为 0\n",
    "        u = torch.zeros(batch_size, self.n_genes, device=self.device)\n",
    "        s = torch.zeros(batch_size, self.n_isoforms, device=self.device)\n",
    "        \n",
    "        for i in range(self.n_steps):\n",
    "            # 当前时刻的参数\n",
    "            alpha_t = alpha_seq[:, i, :]\n",
    "            beta_gene_t = beta_gene_seq[:, i, :]\n",
    "            beta_iso_t = beta_iso_seq[:, i, :]\n",
    "            \n",
    "            # --- 物理方程 (Euler更新) ---\n",
    "            # 这一步完全符合你的想法： u_new = u_old + dt * rate\n",
    "            \n",
    "            # dU = Production - Degradation\n",
    "            du = alpha_t - beta_gene_t * u\n",
    "            \n",
    "            # dS = Splicing - Degradation\n",
    "            # 注意: S的来源是 beta_iso * u_gene\n",
    "            u_expanded = torch.matmul(u, self.g2i_mask)\n",
    "            ds = beta_iso_t * u_expanded - gamma * s\n",
    "            \n",
    "            # 更新状态\n",
    "            u = u + dt * du\n",
    "            s = s + dt * ds\n",
    "            \n",
    "            # 保证非负\n",
    "            u = F.relu(u)\n",
    "            s = F.relu(s)\n",
    "            \n",
    "        return {\n",
    "            \"u_hat\": u, \n",
    "            \"s_hat\": s,\n",
    "            \"t\": T,\n",
    "            \"alpha\": alpha_seq[:, -1, :], # 返回最后一步的alpha供参考\n",
    "            \"beta\": beta_iso_seq[:, -1, :],\n",
    "            \"gamma\": gamma\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fdbb683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda\n",
      "--- Starting Forward Pass ---\n",
      "\n",
      "✅ Forward pass successful!\n",
      "Reconstructed U shape: torch.Size([20, 10]) (Expected: 20, 10)\n",
      "Reconstructed S shape: torch.Size([20, 15]) (Expected: 20, 15)\n",
      "Inferred Time shape:   torch.Size([20, 1]) (Expected: 20, 1)\n",
      "数值检查通过: No NaNs detected.\n",
      "\n",
      "Example U_hat (first cell):\n",
      "[0.98614293 0.6515614  0.70129627 1.1449945  0.72132283]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1. 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Running on: {device}\")\n",
    "\n",
    "# 2. 定义维度 (模拟小规模数据)\n",
    "n_cells = 20\n",
    "n_genes = 10\n",
    "n_isoforms = 15\n",
    "latent_dim = 128\n",
    "hidden_dim = 256\n",
    "\n",
    "# 3. 构造必要的模拟数据\n",
    "# (A) Gene-to-Isoform Mask (必须项)\n",
    "# 逻辑：创建一个 [Genes, Isoforms] 的矩阵，每一列(isoform)只有一个1(属于某个gene)\n",
    "mask_np = np.zeros((n_genes, n_isoforms))\n",
    "# 简单起见，随机给每个 isoform 分配一个 gene\n",
    "for i in range(n_isoforms):\n",
    "    g_idx = np.random.randint(0, n_genes)\n",
    "    mask_np[g_idx, i] = 1\n",
    "g2i_mask = torch.from_numpy(mask_np)\n",
    "\n",
    "# (B) 初始化参数 (scvelo 模拟结果)\n",
    "# 注意形状：Time是(n_cells,), Alpha是(n_genes,), Beta/Gamma是(n_isoforms,)\n",
    "test_time = np.random.rand(n_cells) * 5.0 # 模拟时间 0-5\n",
    "test_alpha = np.random.rand(n_genes)\n",
    "test_beta_iso = np.random.rand(n_isoforms)\n",
    "test_gamma = np.random.rand(n_isoforms)\n",
    "\n",
    "# (C) 模拟输入 Latent z\n",
    "test_z = torch.randn(n_cells, latent_dim).to(device) # [Batch, 128]\n",
    "\n",
    "# (D) 模拟 Batch Indices (如果是全量测试，就是 range(n_cells))\n",
    "# 如果是 DataLoader 里的一个 batch，这里就是该 batch 对应的索引\n",
    "test_indices = torch.arange(n_cells).to(device)\n",
    "\n",
    "# 4. 实例化 Decoder\n",
    "# 注意：你需要确保你的 IsoveloDecoder 类定义在前面已经运行过\n",
    "decoder = IsoveloDecoder(\n",
    "    n_cells=n_cells,\n",
    "    n_genes=n_genes,\n",
    "    n_isoforms=n_isoforms,\n",
    "    g2i_mask=g2i_mask,       # <--- 关键新增\n",
    "    latent_dim=latent_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    n_steps=10,              # 数值积分步数\n",
    "    init_time=test_time,\n",
    "    init_alpha=test_alpha,\n",
    "    init_beta_iso=test_beta_iso,\n",
    "    init_gamma=test_gamma,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "# 5. 运行 Forward 测试\n",
    "print(\"--- Starting Forward Pass ---\")\n",
    "try:\n",
    "    # Forward 需要传入 indices 以获取对应的 Time\n",
    "    outputs = decoder(test_z, test_indices)\n",
    "    \n",
    "    # 6. 检查输出结果\n",
    "    u_hat = outputs[\"u_hat\"]\n",
    "    s_hat = outputs[\"s_hat\"]\n",
    "    pred_time = outputs[\"t\"]\n",
    "    \n",
    "    print(\"\\n✅ Forward pass successful!\")\n",
    "    print(f\"Reconstructed U shape: {u_hat.shape} (Expected: {n_cells}, {n_genes})\")\n",
    "    print(f\"Reconstructed S shape: {s_hat.shape} (Expected: {n_cells}, {n_isoforms})\")\n",
    "    print(f\"Inferred Time shape:   {pred_time.shape} (Expected: {n_cells}, 1)\")\n",
    "    \n",
    "    # 检查是否有 NaN (数值积分常见问题)\n",
    "    if torch.isnan(u_hat).any() or torch.isnan(s_hat).any():\n",
    "        print(\"⚠️ Warning: Output contains NaNs. Check initialization or learning rates.\")\n",
    "    else:\n",
    "        print(\"数值检查通过: No NaNs detected.\")\n",
    "        \n",
    "    # 查看一下实际的数据示例（确保非负）\n",
    "    print(f\"\\nExample U_hat (first cell):\\n{u_hat[0, :5].detach().cpu().numpy()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error during forward pass: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f80c142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'u_hat': tensor([[0.9861, 0.6516, 0.7013, 1.1450, 0.7213, 0.1793, 0.6613, 0.4312, 0.1813,\n",
       "          1.5473],\n",
       "         [0.6498, 0.4466, 0.5104, 0.7735, 0.5817, 0.1442, 0.5040, 0.4521, 0.1635,\n",
       "          1.0480],\n",
       "         [2.6094, 1.1398, 0.7589, 3.1038, 1.0989, 0.2259, 1.7275, 0.4090, 0.1932,\n",
       "          3.4930],\n",
       "         [1.2076, 0.7583, 0.6639, 1.5062, 0.9735, 0.2168, 0.7520, 0.4659, 0.1817,\n",
       "          1.7877],\n",
       "         [2.3933, 0.9522, 0.6311, 3.2229, 0.9823, 0.1757, 1.4936, 0.5275, 0.1734,\n",
       "          3.6760],\n",
       "         [1.1300, 0.6371, 0.7708, 1.1434, 0.6233, 0.2014, 0.6648, 0.3928, 0.1545,\n",
       "          1.6125],\n",
       "         [0.7795, 0.5358, 0.5507, 1.0127, 0.6285, 0.1635, 0.4810, 0.4568, 0.1901,\n",
       "          1.2098],\n",
       "         [1.6265, 1.0227, 0.6674, 2.0116, 0.8331, 0.2312, 1.0964, 0.5128, 0.1816,\n",
       "          2.3464],\n",
       "         [2.4238, 1.1571, 0.7659, 2.8902, 0.8844, 0.1796, 1.6040, 0.5028, 0.1894,\n",
       "          3.5638],\n",
       "         [2.2764, 1.2852, 0.6608, 2.6655, 1.0902, 0.1464, 1.7238, 0.4555, 0.1604,\n",
       "          3.0922],\n",
       "         [0.8952, 0.6651, 0.5937, 1.2498, 0.7722, 0.1607, 0.5802, 0.5116, 0.1623,\n",
       "          1.5359],\n",
       "         [0.7767, 0.4854, 0.5208, 0.9615, 0.6092, 0.1856, 0.4548, 0.4098, 0.1951,\n",
       "          1.1436],\n",
       "         [1.4848, 0.7524, 0.6043, 1.6129, 0.8423, 0.1973, 0.9283, 0.5484, 0.1611,\n",
       "          2.1193],\n",
       "         [2.1895, 0.8306, 0.7225, 2.4704, 1.1458, 0.1639, 1.4448, 0.5468, 0.2243,\n",
       "          2.9916],\n",
       "         [2.2782, 1.2158, 0.6533, 2.5482, 0.7457, 0.2365, 1.4605, 0.4400, 0.1777,\n",
       "          3.5109],\n",
       "         [1.1024, 0.6165, 0.6392, 1.3177, 0.6828, 0.2083, 0.6327, 0.4458, 0.1576,\n",
       "          1.6284],\n",
       "         [2.2637, 1.1189, 0.5724, 2.5153, 1.0191, 0.1868, 1.4310, 0.5624, 0.1488,\n",
       "          3.3593],\n",
       "         [1.8419, 1.1421, 1.0107, 2.4147, 0.9249, 0.2395, 1.4917, 0.6254, 0.1958,\n",
       "          2.7850],\n",
       "         [2.6474, 1.4445, 0.7085, 3.3078, 0.9099, 0.2020, 1.7306, 0.4474, 0.1272,\n",
       "          4.0472],\n",
       "         [1.6265, 0.9654, 0.7105, 1.8890, 0.9910, 0.2577, 0.9959, 0.6194, 0.1690,\n",
       "          2.4093]], device='cuda:0', grad_fn=<ReluBackward0>),\n",
       " 's_hat': tensor([[0.1412, 0.1426, 0.1584, 0.1799, 0.1292, 0.1859, 0.1512, 0.3459, 0.0756,\n",
       "          0.0235, 0.2216, 0.0789, 0.2035, 0.1082, 0.1898],\n",
       "         [0.1137, 0.0703, 0.0658, 0.0919, 0.0851, 0.1038, 0.0876, 0.2630, 0.0352,\n",
       "          0.0128, 0.1581, 0.0481, 0.1316, 0.0497, 0.1167],\n",
       "         [0.2774, 0.5331, 0.4062, 0.3674, 0.1582, 0.4172, 0.2217, 1.0920, 0.1911,\n",
       "          0.0542, 0.5258, 0.1083, 0.2646, 0.2015, 0.4194],\n",
       "         [0.1856, 0.2086, 0.2178, 0.1986, 0.1508, 0.2144, 0.1634, 0.5718, 0.1277,\n",
       "          0.0293, 0.2832, 0.0934, 0.2171, 0.1115, 0.2125],\n",
       "         [0.3937, 0.5475, 0.4790, 0.3191, 0.1554, 0.5525, 0.1781, 1.3841, 0.2250,\n",
       "          0.0655, 0.4751, 0.0879, 0.2372, 0.1821, 0.4336],\n",
       "         [0.1581, 0.1409, 0.1470, 0.1793, 0.1055, 0.1418, 0.1183, 0.4293, 0.0817,\n",
       "          0.0205, 0.2251, 0.0668, 0.1987, 0.0967, 0.2008],\n",
       "         [0.1111, 0.1164, 0.1294, 0.1255, 0.0918, 0.1034, 0.1072, 0.2586, 0.0465,\n",
       "          0.0162, 0.1791, 0.0663, 0.1389, 0.0571, 0.1473],\n",
       "         [0.2381, 0.2981, 0.2979, 0.2565, 0.1684, 0.2801, 0.1912, 0.7393, 0.1186,\n",
       "          0.0373, 0.3538, 0.0908, 0.2298, 0.1780, 0.2875],\n",
       "         [0.3167, 0.4822, 0.4853, 0.3803, 0.1742, 0.5283, 0.2356, 1.2428, 0.2307,\n",
       "          0.0627, 0.5605, 0.0902, 0.2853, 0.2056, 0.4140],\n",
       "         [0.3306, 0.4625, 0.3743, 0.3238, 0.1387, 0.4209, 0.1770, 1.1519, 0.2094,\n",
       "          0.0634, 0.4323, 0.0983, 0.2743, 0.1772, 0.3721],\n",
       "         [0.1584, 0.1205, 0.1906, 0.1470, 0.1034, 0.1370, 0.1235, 0.3684, 0.0550,\n",
       "          0.0177, 0.2006, 0.0581, 0.1259, 0.0812, 0.1872],\n",
       "         [0.1241, 0.0790, 0.0944, 0.0951, 0.0936, 0.1056, 0.1205, 0.2663, 0.0463,\n",
       "          0.0141, 0.1509, 0.0620, 0.1293, 0.0569, 0.1478],\n",
       "         [0.1976, 0.2598, 0.2469, 0.2614, 0.1510, 0.2452, 0.1850, 0.6976, 0.1191,\n",
       "          0.0383, 0.2965, 0.0786, 0.2362, 0.1448, 0.3216],\n",
       "         [0.3225, 0.3343, 0.3657, 0.3219, 0.2052, 0.3993, 0.2758, 0.9409, 0.1543,\n",
       "          0.0485, 0.4916, 0.1150, 0.2537, 0.1332, 0.3968],\n",
       "         [0.3339, 0.4388, 0.3707, 0.3290, 0.1567, 0.3464, 0.2140, 1.0343, 0.1767,\n",
       "          0.0504, 0.4104, 0.1006, 0.2964, 0.1899, 0.4382],\n",
       "         [0.1490, 0.1896, 0.1586, 0.1880, 0.1150, 0.1561, 0.1379, 0.4080, 0.0791,\n",
       "          0.0306, 0.2370, 0.0758, 0.1799, 0.0975, 0.2515],\n",
       "         [0.3557, 0.3876, 0.3529, 0.2790, 0.1560, 0.3922, 0.1818, 1.1172, 0.2063,\n",
       "          0.0612, 0.4157, 0.0860, 0.2237, 0.1833, 0.4209],\n",
       "         [0.3317, 0.4041, 0.3771, 0.3379, 0.1596, 0.4039, 0.2204, 0.9495, 0.1507,\n",
       "          0.0479, 0.4192, 0.0963, 0.3190, 0.1555, 0.4601],\n",
       "         [0.2819, 0.6244, 0.3599, 0.4760, 0.1207, 0.4374, 0.2160, 1.3051, 0.2147,\n",
       "          0.0771, 0.4109, 0.0873, 0.2737, 0.2151, 0.4595],\n",
       "         [0.3036, 0.2740, 0.2978, 0.2741, 0.1462, 0.3401, 0.2101, 0.8143, 0.1643,\n",
       "          0.0473, 0.3754, 0.0837, 0.2325, 0.1705, 0.3694]], device='cuda:0',\n",
       "        grad_fn=<ReluBackward0>),\n",
       " 't': tensor([[1.8198],\n",
       "         [1.2534],\n",
       "         [4.4430],\n",
       "         [2.3463],\n",
       "         [4.6230],\n",
       "         [1.8446],\n",
       "         [1.4615],\n",
       "         [2.8387],\n",
       "         [4.6683],\n",
       "         [4.2852],\n",
       "         [1.7434],\n",
       "         [1.3921],\n",
       "         [2.6054],\n",
       "         [3.6951],\n",
       "         [3.8726],\n",
       "         [1.9841],\n",
       "         [4.1164],\n",
       "         [3.5656],\n",
       "         [4.9068],\n",
       "         [3.1941]], device='cuda:0', grad_fn=<SoftplusBackward0>),\n",
       " 'alpha': tensor([[0.5135, 0.4509, 0.9985, 0.5939, 0.5770, 0.2390, 0.3727, 0.5200, 0.5680,\n",
       "          0.9282],\n",
       "         [0.4618, 0.3809, 0.8211, 0.5708, 0.7077, 0.1796, 0.4470, 0.6427, 0.4937,\n",
       "          0.9035],\n",
       "         [0.5897, 0.4681, 0.8448, 0.7349, 0.6137, 0.1953, 0.4186, 0.4480, 0.5426,\n",
       "          0.7895],\n",
       "         [0.4603, 0.4162, 0.7660, 0.6124, 0.7740, 0.2420, 0.2837, 0.4888, 0.5392,\n",
       "          0.7551],\n",
       "         [0.4519, 0.3798, 0.7238, 0.7246, 0.7020, 0.1778, 0.2928, 0.6851, 0.4442,\n",
       "          0.8233],\n",
       "         [0.6536, 0.4158, 1.0624, 0.5730, 0.5585, 0.2458, 0.3604, 0.4368, 0.4430,\n",
       "          0.9770],\n",
       "         [0.4934, 0.4569, 0.8179, 0.7120, 0.5788, 0.1876, 0.3043, 0.5834, 0.5259,\n",
       "          0.8770],\n",
       "         [0.5739, 0.5520, 0.7725, 0.7500, 0.6056, 0.2511, 0.4151, 0.5673, 0.5558,\n",
       "          0.8799],\n",
       "         [0.4722, 0.4154, 0.8483, 0.5591, 0.5783, 0.1936, 0.3306, 0.6042, 0.5519,\n",
       "          0.7456],\n",
       "         [0.4879, 0.5056, 0.7586, 0.5790, 0.6740, 0.1680, 0.4512, 0.5134, 0.4228,\n",
       "          0.6702],\n",
       "         [0.4523, 0.4702, 0.7434, 0.7622, 0.7000, 0.1710, 0.3053, 0.6615, 0.4368,\n",
       "          0.9900],\n",
       "         [0.5391, 0.3730, 0.7648, 0.7020, 0.6356, 0.2291, 0.3021, 0.5372, 0.5572,\n",
       "          0.8812],\n",
       "         [0.5596, 0.3933, 0.8385, 0.5713, 0.6592, 0.2223, 0.3608, 0.5378, 0.4982,\n",
       "          0.8411],\n",
       "         [0.6149, 0.2920, 0.8406, 0.6694, 0.6927, 0.1363, 0.4278, 0.6105, 0.7087,\n",
       "          0.8410],\n",
       "         [0.5928, 0.5376, 0.8792, 0.6434, 0.5110, 0.2112, 0.3937, 0.5243, 0.4961,\n",
       "          1.0512],\n",
       "         [0.5371, 0.4085, 0.8758, 0.6572, 0.5204, 0.2345, 0.2857, 0.4549, 0.4674,\n",
       "          0.8661],\n",
       "         [0.5200, 0.4071, 0.6767, 0.5550, 0.6557, 0.1909, 0.3356, 0.5674, 0.4260,\n",
       "          0.8606],\n",
       "         [0.4641, 0.5365, 1.1654, 0.6819, 0.6107, 0.1909, 0.4861, 0.6954, 0.5412,\n",
       "          0.7832],\n",
       "         [0.5074, 0.5984, 0.9218, 0.6717, 0.5993, 0.2001, 0.3453, 0.4152, 0.3800,\n",
       "          0.8671],\n",
       "         [0.4456, 0.3977, 0.8291, 0.5159, 0.6426, 0.2578, 0.2691, 0.6501, 0.5019,\n",
       "          0.7397]], device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " 'beta': tensor([[0.3535, 0.3239, 0.3527, 0.3398, 0.7941, 0.4455, 0.8194, 0.5482, 0.4058,\n",
       "          0.1382, 1.0295, 0.4926, 0.4986, 0.7215, 0.3472],\n",
       "         [0.4558, 0.3114, 0.1877, 0.3056, 0.7425, 0.3799, 0.6729, 0.8285, 0.3356,\n",
       "          0.1432, 1.2555, 0.3977, 0.5768, 0.5445, 0.4055],\n",
       "         [0.4002, 0.3482, 0.3810, 0.3271, 0.6120, 0.3501, 0.6288, 0.5182, 0.2684,\n",
       "          0.0896, 1.1022, 0.4670, 0.3697, 0.5047, 0.3877],\n",
       "         [0.3510, 0.3218, 0.3450, 0.2869, 0.7851, 0.3283, 0.6781, 0.5706, 0.4822,\n",
       "          0.1049, 1.0029, 0.5045, 0.4494, 0.4520, 0.3083],\n",
       "         [0.5014, 0.3967, 0.3818, 0.3108, 0.6599, 0.4169, 0.5058, 0.7212, 0.3886,\n",
       "          0.1357, 0.9931, 0.4018, 0.3786, 0.5207, 0.4574],\n",
       "         [0.4433, 0.3143, 0.3352, 0.3063, 0.6677, 0.3158, 0.6333, 0.7954, 0.4126,\n",
       "          0.1023, 1.1796, 0.4361, 0.4455, 0.5574, 0.3435],\n",
       "         [0.3441, 0.4036, 0.3834, 0.3488, 0.5997, 0.2813, 0.6376, 0.5921, 0.3415,\n",
       "          0.1347, 1.0351, 0.4659, 0.4811, 0.4672, 0.4102],\n",
       "         [0.3755, 0.3095, 0.3751, 0.3259, 0.8145, 0.3284, 0.7155, 0.6766, 0.2808,\n",
       "          0.1028, 1.0896, 0.4410, 0.4130, 0.6481, 0.3667],\n",
       "         [0.3965, 0.2931, 0.4040, 0.3272, 0.6946, 0.4064, 0.6795, 0.6782, 0.3839,\n",
       "          0.1224, 1.1610, 0.3794, 0.3938, 0.6000, 0.3651],\n",
       "         [0.4724, 0.2777, 0.3251, 0.3185, 0.6135, 0.3499, 0.5439, 0.5793, 0.4457,\n",
       "          0.1642, 0.9831, 0.4910, 0.4376, 0.5996, 0.3799],\n",
       "         [0.3930, 0.2731, 0.4417, 0.3116, 0.6579, 0.2724, 0.6950, 0.6035, 0.3069,\n",
       "          0.1100, 1.0259, 0.3583, 0.3248, 0.5783, 0.4198],\n",
       "         [0.4657, 0.2874, 0.2856, 0.2646, 0.6536, 0.3418, 0.8141, 0.6905, 0.3365,\n",
       "          0.1085, 0.8687, 0.4495, 0.4863, 0.4519, 0.4674],\n",
       "         [0.3025, 0.3714, 0.3107, 0.3902, 0.8186, 0.2979, 0.8220, 0.7035, 0.3735,\n",
       "          0.1374, 1.0432, 0.4169, 0.4854, 0.6076, 0.4975],\n",
       "         [0.4298, 0.3077, 0.3301, 0.3213, 0.7857, 0.3424, 0.8347, 0.5139, 0.3394,\n",
       "          0.1294, 1.0900, 0.4597, 0.3849, 0.4228, 0.4233],\n",
       "         [0.5253, 0.3016, 0.3781, 0.3469, 0.6720, 0.3112, 0.6960, 0.7421, 0.2851,\n",
       "          0.0931, 0.9499, 0.4742, 0.4921, 0.4989, 0.4992],\n",
       "         [0.3379, 0.4260, 0.3043, 0.3387, 0.6950, 0.2950, 0.7215, 0.6206, 0.3354,\n",
       "          0.1564, 1.1049, 0.4795, 0.4170, 0.4958, 0.4858],\n",
       "         [0.4464, 0.2617, 0.2672, 0.2962, 0.7625, 0.2824, 0.6165, 0.6153, 0.3849,\n",
       "          0.1364, 1.0285, 0.4461, 0.3906, 0.5343, 0.5087],\n",
       "         [0.4083, 0.3154, 0.3253, 0.2664, 0.6419, 0.3328, 0.7033, 0.6341, 0.2583,\n",
       "          0.1000, 1.0015, 0.4164, 0.3836, 0.4052, 0.3985],\n",
       "         [0.3693, 0.3187, 0.2658, 0.4542, 0.6260, 0.3143, 0.8445, 0.6734, 0.2936,\n",
       "          0.1458, 0.9598, 0.5200, 0.4009, 0.5643, 0.4351],\n",
       "         [0.4022, 0.2532, 0.2727, 0.3017, 0.6796, 0.3112, 0.7987, 0.5687, 0.3393,\n",
       "          0.1091, 1.0898, 0.4034, 0.3730, 0.4863, 0.4396]], device='cuda:0',\n",
       "        grad_fn=<SliceBackward0>),\n",
       " 'gamma': tensor([[0.6154, 0.4956, 0.2747, 0.5619, 0.7442, 0.1964, 0.5067, 0.3443, 0.1067,\n",
       "          0.1902, 0.2206, 0.8214, 0.9925, 0.4811, 0.5904]], device='cuda:0',\n",
       "        grad_fn=<SoftplusBackward0>)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b9f1b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 250 genes with high splicing variance.\n"
     ]
    }
   ],
   "source": [
    "prop = adata.obsm['proportion']\n",
    "prop_keep = prop >= 0.02\n",
    "iso_df = adata.obsm['isoform_counts']\n",
    "iso_sums = iso_df.sum(axis=0)\n",
    "keep_mask_count = iso_sums >= 500\n",
    "cells_passing_count = prop_keep.sum(axis=0)\n",
    "keep_passing = cells_passing_count >= 10\n",
    "keep_isoforms = keep_mask_count & keep_passing\n",
    "filtered_iso_df = iso_df.loc[:, keep_isoforms]\n",
    "\n",
    "\n",
    "isoform_names = iso_df.columns\n",
    "try:\n",
    "    gene_map = pd.Series([x.rsplit('_', 1)[0] for x in isoform_names], index=isoform_names)\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error parsing isoform with names '_'. Error: {e}\")\n",
    "\n",
    "remaining_isoforms = gene_map[keep_isoforms.values]\n",
    "new_counts = pd.Series(remaining_isoforms).value_counts(sort=False)\n",
    "\n",
    "adata.var['filtered_n_isoforms'] = 0\n",
    "genes_to_update = new_counts.index.intersection(adata.var_names)\n",
    "adata.var.loc[genes_to_update, 'filtered_n_isoforms'] = new_counts[genes_to_update]\n",
    "\n",
    "adata_hvg = adata.copy()\n",
    "\n",
    "sc.pp.normalize_total(adata_hvg)\n",
    "sc.pp.log1p(adata_hvg)\n",
    "sc.pp.highly_variable_genes(adata_hvg, n_top_genes=500, flavor='seurat')\n",
    "hvg_genes = set(adata_hvg.var_names[adata_hvg.var['highly_variable']])\n",
    "\n",
    "relevant_genes = gene_map[filtered_iso_df.columns].unique()\n",
    "\n",
    "gene_to_iso_cols = {}\n",
    "current_iso_cols = filtered_iso_df.columns\n",
    "temp_gene_map = gene_map[current_iso_cols]\n",
    "    \n",
    "for iso, gene in temp_gene_map.items():\n",
    "    if gene not in gene_to_iso_cols:\n",
    "        gene_to_iso_cols[gene] = []\n",
    "    gene_to_iso_cols[gene].append(iso)\n",
    "\n",
    "current_gene_map = pd.Series([x.rsplit('_', 1)[0] for x in current_iso_cols], index=current_iso_cols)\n",
    "new_gene_counts_df = filtered_iso_df.groupby(current_gene_map.values, axis=1).sum()\n",
    "adata.layers['spliced'] = new_gene_counts_df.values\n",
    "adata.X = adata.layers['spliced'] + adata.layers['unspliced']\n",
    "\n",
    "gene_ids_per_col = current_gene_map[filtered_iso_df.columns]\n",
    "gene_counts_expanded = new_gene_counts_df.loc[:, gene_ids_per_col]\n",
    "gene_counts_expanded.columns = filtered_iso_df.columns \n",
    " \n",
    "new_props = filtered_iso_df / (gene_counts_expanded)\n",
    "iso_variances = new_props.var(axis=0)\n",
    "gene_splicing_scores = iso_variances.groupby(current_gene_map.values, sort=False).mean()\n",
    "\n",
    "multi_iso_genes = adata.var_names[adata.var['filtered_n_isoforms'] > 1]\n",
    "valid_genes = gene_splicing_scores.index.intersection(multi_iso_genes)\n",
    "final_scores = gene_splicing_scores.loc[valid_genes]\n",
    "\n",
    "if not final_scores.empty:\n",
    "    top_splicing_genes = final_scores.sort_values(ascending=False).head(250).index.tolist()\n",
    "    high_splice_genes = set(top_splicing_genes)\n",
    "else:\n",
    "    high_splice_genes = set()\n",
    "        \n",
    "print(f\"Identified {len(high_splice_genes)} genes with high splicing variance.\")\n",
    "final_genes_set = (hvg_genes | high_splice_genes)\n",
    "final_genes = [gene for gene in adata.var_names if gene in final_genes_set]\n",
    "\n",
    "is_isoform_kept = current_gene_map.isin(final_genes_set)\n",
    "    \n",
    "final_iso_counts = filtered_iso_df.loc[:, is_isoform_kept]\n",
    "final_iso_props  = new_props.loc[:, is_isoform_kept]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3abf6f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene0_isoform0</th>\n",
       "      <th>gene0_isoform1</th>\n",
       "      <th>gene0_isoform2</th>\n",
       "      <th>gene0_isoform3</th>\n",
       "      <th>gene0_isoform4</th>\n",
       "      <th>gene1_isoform0</th>\n",
       "      <th>gene1_isoform1</th>\n",
       "      <th>gene1_isoform2</th>\n",
       "      <th>gene2_isoform0</th>\n",
       "      <th>gene2_isoform1</th>\n",
       "      <th>...</th>\n",
       "      <th>gene997_isoform0</th>\n",
       "      <th>gene997_isoform1</th>\n",
       "      <th>gene998_isoform0</th>\n",
       "      <th>gene998_isoform1</th>\n",
       "      <th>gene998_isoform2</th>\n",
       "      <th>gene999_isoform0</th>\n",
       "      <th>gene999_isoform1</th>\n",
       "      <th>gene999_isoform2</th>\n",
       "      <th>gene999_isoform3</th>\n",
       "      <th>gene999_isoform4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cell0</th>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.055434</td>\n",
       "      <td>0.783882</td>\n",
       "      <td>0.157730</td>\n",
       "      <td>0.092371</td>\n",
       "      <td>0.019413</td>\n",
       "      <td>0.888215</td>\n",
       "      <td>0.012982</td>\n",
       "      <td>0.935811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025368</td>\n",
       "      <td>0.974632</td>\n",
       "      <td>0.039979</td>\n",
       "      <td>0.949587</td>\n",
       "      <td>0.010434</td>\n",
       "      <td>0.013327</td>\n",
       "      <td>0.008082</td>\n",
       "      <td>0.897071</td>\n",
       "      <td>0.038516</td>\n",
       "      <td>0.043005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell1</th>\n",
       "      <td>0.069436</td>\n",
       "      <td>0.027645</td>\n",
       "      <td>0.038120</td>\n",
       "      <td>0.711690</td>\n",
       "      <td>0.153109</td>\n",
       "      <td>0.011709</td>\n",
       "      <td>0.150345</td>\n",
       "      <td>0.837946</td>\n",
       "      <td>0.031030</td>\n",
       "      <td>0.945185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041177</td>\n",
       "      <td>0.958823</td>\n",
       "      <td>0.024048</td>\n",
       "      <td>0.907134</td>\n",
       "      <td>0.068818</td>\n",
       "      <td>0.044004</td>\n",
       "      <td>0.076466</td>\n",
       "      <td>0.793215</td>\n",
       "      <td>0.060215</td>\n",
       "      <td>0.026101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell2</th>\n",
       "      <td>0.036947</td>\n",
       "      <td>0.099650</td>\n",
       "      <td>0.039248</td>\n",
       "      <td>0.821082</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.980273</td>\n",
       "      <td>0.006178</td>\n",
       "      <td>0.967000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168463</td>\n",
       "      <td>0.831537</td>\n",
       "      <td>0.061806</td>\n",
       "      <td>0.929543</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>0.042498</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>0.907459</td>\n",
       "      <td>0.024848</td>\n",
       "      <td>0.020361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell3</th>\n",
       "      <td>0.011987</td>\n",
       "      <td>0.062847</td>\n",
       "      <td>0.021297</td>\n",
       "      <td>0.891863</td>\n",
       "      <td>0.012006</td>\n",
       "      <td>0.124549</td>\n",
       "      <td>0.013793</td>\n",
       "      <td>0.861658</td>\n",
       "      <td>0.005194</td>\n",
       "      <td>0.921849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.999571</td>\n",
       "      <td>0.036014</td>\n",
       "      <td>0.906556</td>\n",
       "      <td>0.057429</td>\n",
       "      <td>0.080205</td>\n",
       "      <td>0.022818</td>\n",
       "      <td>0.845171</td>\n",
       "      <td>0.019799</td>\n",
       "      <td>0.032007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell4</th>\n",
       "      <td>0.027065</td>\n",
       "      <td>0.005179</td>\n",
       "      <td>0.049520</td>\n",
       "      <td>0.912792</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.011394</td>\n",
       "      <td>0.007370</td>\n",
       "      <td>0.981235</td>\n",
       "      <td>0.129561</td>\n",
       "      <td>0.869357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012906</td>\n",
       "      <td>0.987094</td>\n",
       "      <td>0.020643</td>\n",
       "      <td>0.940613</td>\n",
       "      <td>0.038743</td>\n",
       "      <td>0.040638</td>\n",
       "      <td>0.100550</td>\n",
       "      <td>0.802722</td>\n",
       "      <td>0.038924</td>\n",
       "      <td>0.017165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell1995</th>\n",
       "      <td>0.027365</td>\n",
       "      <td>0.004360</td>\n",
       "      <td>0.055163</td>\n",
       "      <td>0.787518</td>\n",
       "      <td>0.125594</td>\n",
       "      <td>0.138441</td>\n",
       "      <td>0.098001</td>\n",
       "      <td>0.763558</td>\n",
       "      <td>0.083523</td>\n",
       "      <td>0.898684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846623</td>\n",
       "      <td>0.153377</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>0.227879</td>\n",
       "      <td>0.766956</td>\n",
       "      <td>0.033292</td>\n",
       "      <td>0.100374</td>\n",
       "      <td>0.150069</td>\n",
       "      <td>0.050855</td>\n",
       "      <td>0.665410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell1996</th>\n",
       "      <td>0.051143</td>\n",
       "      <td>0.027791</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.870665</td>\n",
       "      <td>0.049907</td>\n",
       "      <td>0.010933</td>\n",
       "      <td>0.008555</td>\n",
       "      <td>0.980512</td>\n",
       "      <td>0.088887</td>\n",
       "      <td>0.907819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038461</td>\n",
       "      <td>0.961539</td>\n",
       "      <td>0.071915</td>\n",
       "      <td>0.886500</td>\n",
       "      <td>0.041585</td>\n",
       "      <td>0.040483</td>\n",
       "      <td>0.017764</td>\n",
       "      <td>0.804311</td>\n",
       "      <td>0.082368</td>\n",
       "      <td>0.055074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell1997</th>\n",
       "      <td>0.035424</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.029545</td>\n",
       "      <td>0.888807</td>\n",
       "      <td>0.018415</td>\n",
       "      <td>0.131065</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>0.864425</td>\n",
       "      <td>0.098264</td>\n",
       "      <td>0.833042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038984</td>\n",
       "      <td>0.961016</td>\n",
       "      <td>0.035882</td>\n",
       "      <td>0.937306</td>\n",
       "      <td>0.026813</td>\n",
       "      <td>0.008932</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.814616</td>\n",
       "      <td>0.154557</td>\n",
       "      <td>0.018516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell1998</th>\n",
       "      <td>0.038887</td>\n",
       "      <td>0.011101</td>\n",
       "      <td>0.057584</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.030996</td>\n",
       "      <td>0.009846</td>\n",
       "      <td>0.026444</td>\n",
       "      <td>0.963710</td>\n",
       "      <td>0.076589</td>\n",
       "      <td>0.886500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138428</td>\n",
       "      <td>0.861572</td>\n",
       "      <td>0.005505</td>\n",
       "      <td>0.802444</td>\n",
       "      <td>0.192051</td>\n",
       "      <td>0.015179</td>\n",
       "      <td>0.015678</td>\n",
       "      <td>0.766043</td>\n",
       "      <td>0.048797</td>\n",
       "      <td>0.154303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell1999</th>\n",
       "      <td>0.059046</td>\n",
       "      <td>0.060366</td>\n",
       "      <td>0.015645</td>\n",
       "      <td>0.839589</td>\n",
       "      <td>0.025354</td>\n",
       "      <td>0.004215</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.994039</td>\n",
       "      <td>0.010712</td>\n",
       "      <td>0.973174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041886</td>\n",
       "      <td>0.958114</td>\n",
       "      <td>0.023167</td>\n",
       "      <td>0.867242</td>\n",
       "      <td>0.109591</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>0.015677</td>\n",
       "      <td>0.861676</td>\n",
       "      <td>0.069649</td>\n",
       "      <td>0.037507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3468 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          gene0_isoform0  gene0_isoform1  gene0_isoform2  gene0_isoform3  \\\n",
       "cell0           0.002771        0.000183        0.055434        0.783882   \n",
       "cell1           0.069436        0.027645        0.038120        0.711690   \n",
       "cell2           0.036947        0.099650        0.039248        0.821082   \n",
       "cell3           0.011987        0.062847        0.021297        0.891863   \n",
       "cell4           0.027065        0.005179        0.049520        0.912792   \n",
       "...                  ...             ...             ...             ...   \n",
       "cell1995        0.027365        0.004360        0.055163        0.787518   \n",
       "cell1996        0.051143        0.027791        0.000495        0.870665   \n",
       "cell1997        0.035424        0.027809        0.029545        0.888807   \n",
       "cell1998        0.038887        0.011101        0.057584        0.861432   \n",
       "cell1999        0.059046        0.060366        0.015645        0.839589   \n",
       "\n",
       "          gene0_isoform4  gene1_isoform0  gene1_isoform1  gene1_isoform2  \\\n",
       "cell0           0.157730        0.092371        0.019413        0.888215   \n",
       "cell1           0.153109        0.011709        0.150345        0.837946   \n",
       "cell2           0.003073        0.019592        0.000135        0.980273   \n",
       "cell3           0.012006        0.124549        0.013793        0.861658   \n",
       "cell4           0.005445        0.011394        0.007370        0.981235   \n",
       "...                  ...             ...             ...             ...   \n",
       "cell1995        0.125594        0.138441        0.098001        0.763558   \n",
       "cell1996        0.049907        0.010933        0.008555        0.980512   \n",
       "cell1997        0.018415        0.131065        0.004510        0.864425   \n",
       "cell1998        0.030996        0.009846        0.026444        0.963710   \n",
       "cell1999        0.025354        0.004215        0.001746        0.994039   \n",
       "\n",
       "          gene2_isoform0  gene2_isoform1  ...  gene997_isoform0  \\\n",
       "cell0           0.012982        0.935811  ...          0.025368   \n",
       "cell1           0.031030        0.945185  ...          0.041177   \n",
       "cell2           0.006178        0.967000  ...          0.168463   \n",
       "cell3           0.005194        0.921849  ...          0.000429   \n",
       "cell4           0.129561        0.869357  ...          0.012906   \n",
       "...                  ...             ...  ...               ...   \n",
       "cell1995        0.083523        0.898684  ...          0.846623   \n",
       "cell1996        0.088887        0.907819  ...          0.038461   \n",
       "cell1997        0.098264        0.833042  ...          0.038984   \n",
       "cell1998        0.076589        0.886500  ...          0.138428   \n",
       "cell1999        0.010712        0.973174  ...          0.041886   \n",
       "\n",
       "          gene997_isoform1  gene998_isoform0  gene998_isoform1  \\\n",
       "cell0             0.974632          0.039979          0.949587   \n",
       "cell1             0.958823          0.024048          0.907134   \n",
       "cell2             0.831537          0.061806          0.929543   \n",
       "cell3             0.999571          0.036014          0.906556   \n",
       "cell4             0.987094          0.020643          0.940613   \n",
       "...                    ...               ...               ...   \n",
       "cell1995          0.153377          0.005166          0.227879   \n",
       "cell1996          0.961539          0.071915          0.886500   \n",
       "cell1997          0.961016          0.035882          0.937306   \n",
       "cell1998          0.861572          0.005505          0.802444   \n",
       "cell1999          0.958114          0.023167          0.867242   \n",
       "\n",
       "          gene998_isoform2  gene999_isoform0  gene999_isoform1  \\\n",
       "cell0             0.010434          0.013327          0.008082   \n",
       "cell1             0.068818          0.044004          0.076466   \n",
       "cell2             0.008651          0.042498          0.004834   \n",
       "cell3             0.057429          0.080205          0.022818   \n",
       "cell4             0.038743          0.040638          0.100550   \n",
       "...                    ...               ...               ...   \n",
       "cell1995          0.766956          0.033292          0.100374   \n",
       "cell1996          0.041585          0.040483          0.017764   \n",
       "cell1997          0.026813          0.008932          0.003378   \n",
       "cell1998          0.192051          0.015179          0.015678   \n",
       "cell1999          0.109591          0.015491          0.015677   \n",
       "\n",
       "          gene999_isoform2  gene999_isoform3  gene999_isoform4  \n",
       "cell0             0.897071          0.038516          0.043005  \n",
       "cell1             0.793215          0.060215          0.026101  \n",
       "cell2             0.907459          0.024848          0.020361  \n",
       "cell3             0.845171          0.019799          0.032007  \n",
       "cell4             0.802722          0.038924          0.017165  \n",
       "...                    ...               ...               ...  \n",
       "cell1995          0.150069          0.050855          0.665410  \n",
       "cell1996          0.804311          0.082368          0.055074  \n",
       "cell1997          0.814616          0.154557          0.018516  \n",
       "cell1998          0.766043          0.048797          0.154303  \n",
       "cell1999          0.861676          0.069649          0.037507  \n",
       "\n",
       "[2000 rows x 3468 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obsm['proportion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1591e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gene750    0.0\n",
       "gene751    0.0\n",
       "gene752    0.0\n",
       "gene753    0.0\n",
       "gene754    0.0\n",
       "          ... \n",
       "gene995    0.0\n",
       "gene996    0.0\n",
       "gene997    0.0\n",
       "gene998    0.0\n",
       "gene999    0.0\n",
       "Length: 250, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_splicing_scores[750:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f26d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda1905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
