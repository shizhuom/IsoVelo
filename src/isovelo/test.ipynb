{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e2921a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import scvelo as scv\n",
    "from scvi.nn import Encoder, FCLayers\n",
    "import anndata\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96dcd9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0006a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = anndata.read_h5ad('../../../simulated_data_continuous_0.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe9f9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 2000 × 1000\n",
      "    obs: 'cell_state', 'pseudotime'\n",
      "    var: 'gene_category', 'n_isoforms'\n",
      "    uns: 'proportions_ground_truth', 'proportions_observed', 'spliced_isoform_counts'\n",
      "    layers: 'alpha', 'beta', 'gamma', 'spliced', 'unspliced'\n",
      "Index(['gene0', 'gene1', 'gene2', 'gene3', 'gene4', 'gene5', 'gene6', 'gene7',\n",
      "       'gene8', 'gene9',\n",
      "       ...\n",
      "       'gene990', 'gene991', 'gene992', 'gene993', 'gene994', 'gene995',\n",
      "       'gene996', 'gene997', 'gene998', 'gene999'],\n",
      "      dtype='object', length=1000)\n",
      "Index(['cell0', 'cell1', 'cell2', 'cell3', 'cell4', 'cell5', 'cell6', 'cell7',\n",
      "       'cell8', 'cell9',\n",
      "       ...\n",
      "       'cell1990', 'cell1991', 'cell1992', 'cell1993', 'cell1994', 'cell1995',\n",
      "       'cell1996', 'cell1997', 'cell1998', 'cell1999'],\n",
      "      dtype='object', length=2000)\n"
     ]
    }
   ],
   "source": [
    "print(adata)\n",
    "adata.var_names = 'gene' + adata.var_names\n",
    "adata.obs_names = 'cell' + adata.obs_names\n",
    "print(adata.var_names)\n",
    "print(adata.obs_names)\n",
    "adata.uns['proportions_ground_truth'] = {f\"gene{int(key)}\": value for key, value in adata.uns['proportions_ground_truth'].items()}\n",
    "adata.uns['proportions_observed'] = {f\"gene{int(key)}\": value for key, value in adata.uns['proportions_observed'].items()}\n",
    "adata.uns['spliced_isoform_counts'] = {f\"gene{int(key)}\": value for key, value in adata.uns['spliced_isoform_counts'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ea3ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['proportions_ground_truth']\n",
    "iso_count = []\n",
    "iso_cols =[]\n",
    "p_data = []\n",
    "for gene_name in adata.var_names:\n",
    "    p = adata.uns['proportions_ground_truth'][gene_name]\n",
    "    p_data.append(p)\n",
    "    iso = adata.uns['spliced_isoform_counts'][gene_name]\n",
    "    iso_count.append(iso)\n",
    "    iso_cols += [f\"{gene_name}_isoform{i}\" for i in range(p.shape[0])]\n",
    "iso = np.vstack(iso_count).T\n",
    "proportion = np.vstack(p_data).T\n",
    "adata.obsm[\"isoform_counts\"] = pd.DataFrame(iso, index = adata.obs_names, columns = iso_cols)\n",
    "adata.obsm[\"proportion\"] = pd.DataFrame(proportion, index = adata.obs_names, columns = iso_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a9d92df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gene0      5\n",
       "gene1      3\n",
       "gene2      3\n",
       "gene3      4\n",
       "gene4      5\n",
       "          ..\n",
       "gene995    2\n",
       "gene996    4\n",
       "gene997    2\n",
       "gene998    3\n",
       "gene999    5\n",
       "Name: n_isoforms, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata\n",
    "adata.var['n_isoforms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a63b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsoDataset(Dataset):\n",
    "    def __init__(self, adata):\n",
    "        # Get Unspliced counts (G genes)\n",
    "        U = adata.layers[\"unspliced\"]\n",
    "        if sp.issparse(U):\n",
    "            U = U.toarray()\n",
    "        \n",
    "        # Get Isoform counts (I isoforms)\n",
    "        # Assume that adata.obsm[\"isoform_counts\"] includes spliced isoform count\n",
    "        I = adata.obsm[\"isoform_counts\"]\n",
    "        if hasattr(I, \"values\"): \n",
    "            I = I.values\n",
    "        if sp.issparse(I):        \n",
    "            I = I.toarray()\n",
    "            \n",
    "        # Merge: Cells x (Genes + Isoforms)\n",
    "        # Note: the input of the Encoder should be G + I\n",
    "        X = np.hstack([U, I]).astype(np.float32) \n",
    "        self.X = torch.from_numpy(X)\n",
    "        self.n_cells = self.X.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_cells\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the data and index\n",
    "        return self.X[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8f14b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsoveloEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    Encodes U (unspliced) and Isoform counts into a latent cell embedding.\n",
    "    Inherits from scvi.nn.Encoder to leverage its VAE structure.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 input_dim:int, \n",
    "                 hidden_dim=32, \n",
    "                 latent_dim = 128, \n",
    "                 n_layers=2, \n",
    "                 dropout_rate=0.1, \n",
    "                 distribution=\"normal\", \n",
    "                 use_batch_norm=True, \n",
    "                 use_layer_norm=False,\n",
    "                 var_activation=nn.Softplus(),\n",
    "                 activation_fn=nn.ReLU,\n",
    "                 **kwargs):\n",
    "        super().__init__(n_input=input_dim, \n",
    "                         n_output=latent_dim,\n",
    "                         n_layers=n_layers,\n",
    "                         n_hidden=hidden_dim,\n",
    "                         dropout_rate=dropout_rate,\n",
    "                         distribution=distribution,\n",
    "                         use_batch_norm=use_batch_norm,\n",
    "                         use_layer_norm=use_layer_norm,\n",
    "                         var_activation=var_activation,\n",
    "                         activation_fn=activation_fn,\n",
    "                         **kwargs\n",
    "                         )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, *cat_list: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        :param x: Concatenated tensor of [U, Isoforms]\n",
    "        :return: A dictionary with 'qz_m', 'qz_v', 'z'\n",
    "        \"\"\"\n",
    "        # Encode x to get latent parameters\n",
    "        qz_m, qz_v, z = super().forward(x, *cat_list)\n",
    "        \n",
    "        return {\"qz_m\": qz_m, \"qz_v\": qz_v, \"z\": z}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d794e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder_from_adata(adata, **enc_kwargs):\n",
    "    U = adata.layers[\"unspliced\"]\n",
    "    g = U.shape[1]\n",
    "    i = adata.obsm[\"isoform_counts\"].shape[1]\n",
    "    enc = IsoveloEncoder(input_dim=g + i, **enc_kwargs)\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4818e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0349a480",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsoveloDecoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_cells: int,\n",
    "                 n_genes: int,\n",
    "                 n_isoforms: int,\n",
    "                 latent_dim: int = 128,\n",
    "                 hidden_dim: int = 256,\n",
    "                 # Initialization values provided by scVelo\n",
    "                 init_time: np.ndarray = None,      # shape: (n_cells, )\n",
    "                 init_alpha: np.ndarray = None,     # shape: (n_genes, )\n",
    "                 init_beta_iso: np.ndarray = None,  # shape: (n_isoforms, ) <- (beta_gene * proportion)\n",
    "                 init_gamma: np.ndarray = None,     # shape: (n_isoforms, ) <- (gamma_gene * proportion)\n",
    "                 device = torch.device):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        def inverse_softplus(x_np):\n",
    "            x_safe = np.maximum(x_np, 1e-6)\n",
    "            return np.log(np.exp(x_safe)-1)\n",
    "\n",
    "        self.n_genes = n_genes\n",
    "        self.n_isoforms = n_isoforms\n",
    "        self.device = device\n",
    "\n",
    "        # --- A. Cell Time (t) ---\n",
    "        # independent parameters, not rely on z (cell * 1)\n",
    "        self.cell_time = nn.Parameter(torch.randn(n_cells, 1)) \n",
    "        if init_time is not None:\n",
    "            # Initialize with the scvelo output\n",
    "            self.cell_time.data.copy_(torch.from_numpy(init_time).float().unsqueeze(1))\n",
    "\n",
    "        # --- B. Gamma (γ) ---\n",
    "        # independent parameters, not rely on z (1 * isoform)\n",
    "        self.gamma = nn.Parameter(torch.ones(1, n_isoforms))\n",
    "        if init_gamma is not None:\n",
    "            # Initialize with the scvelo output\n",
    "            inv_gamma = inverse_softplus(init_gamma)\n",
    "            self.gamma.data.copy_(torch.from_numpy(inv_gamma).float().unsqueeze(0))\n",
    "\n",
    "        # --- C. Alpha Network (α) ---\n",
    "        # Input: z -> Output: Alpha (Cell * Gene)\n",
    "        self.alpha_fc1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.alpha_fc2 = nn.Linear(hidden_dim, n_genes) # 最后一层\n",
    "        \n",
    "        # Initialize the bias of the alpha\n",
    "        if init_alpha is not None:\n",
    "            # Initial weights should be small, the initial values should be determined mainly by the scvelo bias\n",
    "            nn.init.xavier_normal_(self.alpha_fc2.weight, gain=0.01)\n",
    "            # Set the bias to scvelo output (usually need to get log or inverse softplus, depending on the activation function)\n",
    "            # Assume that using Softplus activation. For simplicity, set to scvelo output, training will approximate these values\n",
    "            inv_alpha = inverse_softplus(init_alpha)\n",
    "            self.alpha_fc2.bias.data.copy_(torch.from_numpy(inv_alpha).float())\n",
    "\n",
    "        # --- D. Beta Network (β) ---\n",
    "        # Input: z -> Output: Beta (Cell * Isoform)\n",
    "        self.beta_fc1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.beta_fc2 = nn.Linear(hidden_dim, n_isoforms) \n",
    "        \n",
    "        # Initialize the bias of the beta\n",
    "        if init_beta_iso is not None:\n",
    "            nn.init.xavier_normal_(self.beta_fc2.weight, gain=0.01)\n",
    "            # Similar with alpha, here it should be isoform level beta\n",
    "            inv_beta = inverse_softplus(init_beta_iso)\n",
    "            self.beta_fc2.bias.data.copy_(torch.from_numpy(inv_beta).float())\n",
    "\n",
    "    def forward(self, z: torch.Tensor, cell_indices = None):\n",
    "        \"\"\"\n",
    "        z: [Batch, Latent_dim]\n",
    "        cell_indices: [Batch]\n",
    "        \"\"\"\n",
    "        # 1. Get cell time\n",
    "        if cell_indices is not None:\n",
    "            t = self.cell_time[cell_indices] # [Batch, 1]\n",
    "        else:\n",
    "            t = self.cell_time\n",
    "\n",
    "        # 2. Get alpha (non-negative)\n",
    "        h_alpha = F.relu(self.alpha_fc1(z))\n",
    "        alpha = F.softplus(self.alpha_fc2(h_alpha)) # [Batch, n_genes]\n",
    "\n",
    "        # 3. Get beta (non-negative)\n",
    "        h_beta = F.relu(self.beta_fc1(z))\n",
    "        beta = F.softplus(self.beta_fc2(h_beta))   # [Batch, n_isoforms]\n",
    "\n",
    "        # 4. Get gamma (non-negative)\n",
    "        gamma = F.softplus(self.gamma)             # [1, n_isoforms]\n",
    "\n",
    "        return {\"cell_time\": t, \"gene_alpha\": alpha, \"isoform_beta\": beta, \"isoform_gamma\":gamma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46e21616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cell_time': Parameter containing:\n",
       " tensor([[0.3647],\n",
       "         [0.9789],\n",
       "         [0.8849],\n",
       "         [0.9412],\n",
       "         [0.7309],\n",
       "         [0.7280],\n",
       "         [0.5466],\n",
       "         [0.4591],\n",
       "         [0.2717],\n",
       "         [0.7356],\n",
       "         [0.2825],\n",
       "         [0.4853],\n",
       "         [0.8373],\n",
       "         [0.4981],\n",
       "         [0.4323],\n",
       "         [0.3400],\n",
       "         [0.4265],\n",
       "         [0.9966],\n",
       "         [0.1515],\n",
       "         [0.1439]], device='cuda:0', requires_grad=True),\n",
       " 'gene_alpha': tensor([[0.5238, 0.0322, 0.2024, 0.6503, 0.8556, 0.5879, 0.7142, 0.2903, 0.6915,\n",
       "          0.3397],\n",
       "         [0.5224, 0.0321, 0.2030, 0.6509, 0.8557, 0.5864, 0.7158, 0.2911, 0.6913,\n",
       "          0.3395],\n",
       "         [0.5228, 0.0321, 0.2024, 0.6513, 0.8538, 0.5879, 0.7132, 0.2909, 0.6909,\n",
       "          0.3404],\n",
       "         [0.5229, 0.0322, 0.2023, 0.6506, 0.8556, 0.5897, 0.7131, 0.2906, 0.6900,\n",
       "          0.3397],\n",
       "         [0.5230, 0.0322, 0.2032, 0.6507, 0.8555, 0.5883, 0.7140, 0.2905, 0.6890,\n",
       "          0.3400],\n",
       "         [0.5239, 0.0321, 0.2029, 0.6498, 0.8560, 0.5876, 0.7138, 0.2913, 0.6909,\n",
       "          0.3389],\n",
       "         [0.5217, 0.0321, 0.2021, 0.6507, 0.8559, 0.5885, 0.7130, 0.2908, 0.6899,\n",
       "          0.3395],\n",
       "         [0.5231, 0.0321, 0.2022, 0.6500, 0.8552, 0.5860, 0.7152, 0.2908, 0.6906,\n",
       "          0.3399],\n",
       "         [0.5220, 0.0322, 0.2023, 0.6498, 0.8549, 0.5883, 0.7136, 0.2906, 0.6901,\n",
       "          0.3402],\n",
       "         [0.5233, 0.0322, 0.2029, 0.6514, 0.8556, 0.5882, 0.7146, 0.2913, 0.6907,\n",
       "          0.3398],\n",
       "         [0.5228, 0.0321, 0.2026, 0.6512, 0.8547, 0.5880, 0.7144, 0.2907, 0.6903,\n",
       "          0.3393],\n",
       "         [0.5224, 0.0321, 0.2023, 0.6507, 0.8548, 0.5865, 0.7157, 0.2915, 0.6903,\n",
       "          0.3400],\n",
       "         [0.5225, 0.0322, 0.2023, 0.6504, 0.8544, 0.5872, 0.7145, 0.2907, 0.6898,\n",
       "          0.3404],\n",
       "         [0.5227, 0.0322, 0.2022, 0.6512, 0.8548, 0.5862, 0.7154, 0.2909, 0.6907,\n",
       "          0.3396],\n",
       "         [0.5225, 0.0322, 0.2030, 0.6503, 0.8566, 0.5892, 0.7144, 0.2904, 0.6907,\n",
       "          0.3400],\n",
       "         [0.5230, 0.0320, 0.2022, 0.6512, 0.8559, 0.5884, 0.7145, 0.2911, 0.6905,\n",
       "          0.3401],\n",
       "         [0.5222, 0.0322, 0.2027, 0.6511, 0.8557, 0.5866, 0.7150, 0.2914, 0.6912,\n",
       "          0.3401],\n",
       "         [0.5220, 0.0321, 0.2021, 0.6500, 0.8548, 0.5866, 0.7143, 0.2911, 0.6915,\n",
       "          0.3398],\n",
       "         [0.5223, 0.0321, 0.2026, 0.6519, 0.8542, 0.5881, 0.7148, 0.2907, 0.6906,\n",
       "          0.3395],\n",
       "         [0.5229, 0.0321, 0.2029, 0.6512, 0.8558, 0.5869, 0.7146, 0.2910, 0.6907,\n",
       "          0.3395]], device='cuda:0', grad_fn=<SoftplusBackward0>),\n",
       " 'isoform_beta': tensor([[0.7560, 0.0971, 0.0792, 0.8749, 0.6793, 0.4722, 0.3939, 0.4315, 0.0819,\n",
       "          0.3892, 0.9428, 0.9780, 0.0393, 0.3361, 0.4114],\n",
       "         [0.7567, 0.0971, 0.0791, 0.8745, 0.6804, 0.4714, 0.3936, 0.4303, 0.0820,\n",
       "          0.3893, 0.9413, 0.9772, 0.0392, 0.3353, 0.4109],\n",
       "         [0.7560, 0.0971, 0.0791, 0.8743, 0.6789, 0.4708, 0.3939, 0.4310, 0.0822,\n",
       "          0.3889, 0.9421, 0.9756, 0.0392, 0.3364, 0.4112],\n",
       "         [0.7550, 0.0972, 0.0791, 0.8748, 0.6788, 0.4723, 0.3943, 0.4305, 0.0821,\n",
       "          0.3901, 0.9424, 0.9756, 0.0392, 0.3347, 0.4104],\n",
       "         [0.7565, 0.0969, 0.0790, 0.8754, 0.6791, 0.4721, 0.3938, 0.4307, 0.0819,\n",
       "          0.3897, 0.9417, 0.9768, 0.0393, 0.3362, 0.4108],\n",
       "         [0.7560, 0.0969, 0.0793, 0.8749, 0.6790, 0.4719, 0.3947, 0.4297, 0.0821,\n",
       "          0.3898, 0.9423, 0.9770, 0.0393, 0.3360, 0.4110],\n",
       "         [0.7558, 0.0971, 0.0793, 0.8745, 0.6792, 0.4719, 0.3939, 0.4318, 0.0817,\n",
       "          0.3893, 0.9428, 0.9777, 0.0392, 0.3345, 0.4104],\n",
       "         [0.7573, 0.0971, 0.0792, 0.8741, 0.6807, 0.4717, 0.3941, 0.4315, 0.0819,\n",
       "          0.3888, 0.9426, 0.9782, 0.0393, 0.3352, 0.4108],\n",
       "         [0.7561, 0.0974, 0.0791, 0.8753, 0.6794, 0.4727, 0.3941, 0.4302, 0.0821,\n",
       "          0.3906, 0.9419, 0.9772, 0.0392, 0.3358, 0.4100],\n",
       "         [0.7568, 0.0970, 0.0792, 0.8743, 0.6802, 0.4718, 0.3937, 0.4310, 0.0820,\n",
       "          0.3902, 0.9429, 0.9750, 0.0391, 0.3350, 0.4105],\n",
       "         [0.7556, 0.0968, 0.0791, 0.8742, 0.6798, 0.4720, 0.3935, 0.4307, 0.0819,\n",
       "          0.3895, 0.9418, 0.9771, 0.0393, 0.3362, 0.4103],\n",
       "         [0.7557, 0.0969, 0.0794, 0.8753, 0.6794, 0.4712, 0.3943, 0.4303, 0.0819,\n",
       "          0.3888, 0.9421, 0.9762, 0.0392, 0.3362, 0.4109],\n",
       "         [0.7551, 0.0972, 0.0790, 0.8729, 0.6796, 0.4723, 0.3942, 0.4308, 0.0820,\n",
       "          0.3897, 0.9414, 0.9773, 0.0393, 0.3353, 0.4099],\n",
       "         [0.7559, 0.0973, 0.0792, 0.8759, 0.6800, 0.4722, 0.3941, 0.4310, 0.0821,\n",
       "          0.3899, 0.9425, 0.9780, 0.0392, 0.3354, 0.4112],\n",
       "         [0.7547, 0.0972, 0.0793, 0.8741, 0.6793, 0.4726, 0.3939, 0.4306, 0.0822,\n",
       "          0.3891, 0.9430, 0.9785, 0.0392, 0.3359, 0.4107],\n",
       "         [0.7562, 0.0970, 0.0791, 0.8732, 0.6797, 0.4712, 0.3941, 0.4297, 0.0821,\n",
       "          0.3896, 0.9418, 0.9771, 0.0392, 0.3367, 0.4099],\n",
       "         [0.7568, 0.0969, 0.0793, 0.8755, 0.6789, 0.4722, 0.3940, 0.4310, 0.0821,\n",
       "          0.3891, 0.9421, 0.9777, 0.0393, 0.3355, 0.4117],\n",
       "         [0.7567, 0.0970, 0.0794, 0.8738, 0.6804, 0.4719, 0.3946, 0.4311, 0.0819,\n",
       "          0.3886, 0.9438, 0.9762, 0.0392, 0.3347, 0.4099],\n",
       "         [0.7569, 0.0971, 0.0791, 0.8754, 0.6795, 0.4715, 0.3944, 0.4311, 0.0822,\n",
       "          0.3885, 0.9420, 0.9792, 0.0393, 0.3355, 0.4103],\n",
       "         [0.7551, 0.0970, 0.0791, 0.8731, 0.6788, 0.4723, 0.3939, 0.4313, 0.0820,\n",
       "          0.3895, 0.9428, 0.9756, 0.0393, 0.3357, 0.4106]], device='cuda:0',\n",
       "        grad_fn=<SoftplusBackward0>),\n",
       " 'isoform_gamma': tensor([[0.4354, 0.4134, 0.1991, 0.8076, 0.4039, 0.3544, 0.1250, 0.2084, 0.9240,\n",
       "          0.8602, 0.0430, 0.6004, 0.3026, 0.7282, 0.5580]], device='cuda:0',\n",
       "        grad_fn=<SoftplusBackward0>)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scvelo.tools import latent_time\n",
    "\n",
    "\n",
    "model = build_encoder_from_adata(adata, hidden_dim=32, latent_dim = 128).to(device)\n",
    "dataset = IsoDataset(adata)\n",
    "outputs = model(dataset.X.to(device))\n",
    "test_time = np.random.rand(20)\n",
    "test_alpha = np.random.rand(10)\n",
    "test_beta = np.random.rand(15)\n",
    "test_gamma = np.random.rand(15)\n",
    "test_z = np.random.rand(20,128)\n",
    "test_z = torch.from_numpy(test_z).float().to(device)\n",
    "decoder = IsoveloDecoder(n_cells=20, n_genes=10, n_isoforms=15, latent_dim=128, hidden_dim=256, init_time=test_time, init_alpha=test_alpha, init_beta_iso=test_beta, init_gamma=test_gamma, device = device).to(device)\n",
    "decoder.cell_time.detach().cpu().numpy()\n",
    "decoder(test_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045b47c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=True,          # Shuffle each epoch\n",
    "    num_workers=0,         # Depends on the number of cpus\n",
    "    pin_memory=True        # If trained with GPU\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# After training, store all intermediate parameters\n",
    "model.eval()\n",
    "X_tensor = dataset.X.to(device) \n",
    "\n",
    "with torch.no_grad():\n",
    "    results = model(X_tensor)\n",
    "\n",
    "z = results[\"z\"].cpu().numpy()\n",
    "qz_m = results[\"qz_m\"].cpu().numpy()\n",
    "qz_v = results[\"qz_v\"].cpu().numpy()\n",
    "\n",
    "adata.obsm[\"X_isovelo_z\"] = z\n",
    "adata.obsm[\"latent_qz_m\"] = qz_m \n",
    "adata.obsm[\"latent_qz_v\"] = qz_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cfc418",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c69369c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class IsoveloDecoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 n_cells: int, \n",
    "                 n_genes: int, \n",
    "                 n_isoforms: int, \n",
    "                 g2i_mask: torch.Tensor, \n",
    "                 latent_dim: int = 128, \n",
    "                 hidden_dim: int = 256,\n",
    "                 n_steps: int = 10,  # 把时间切成10份来积分\n",
    "                 init_time: np.ndarray = None,       \n",
    "                 init_alpha: np.ndarray = None,      \n",
    "                 init_beta_iso: np.ndarray = None,   \n",
    "                 init_gamma: np.ndarray = None,      \n",
    "                 device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.n_genes = n_genes\n",
    "        self.n_isoforms = n_isoforms\n",
    "        self.n_steps = n_steps # 积分步数\n",
    "        self.device = device\n",
    "        \n",
    "        self.register_buffer('g2i_mask', g2i_mask.float().to(device)) \n",
    "\n",
    "        # --- Parameters ---\n",
    "        # 1. Cell Time (每个细胞独立的时间)\n",
    "        if init_time is not None:\n",
    "            t_init = torch.from_numpy(init_time).float().view(-1, 1)\n",
    "        else:\n",
    "            t_init = torch.rand(n_cells, 1) * 5.0\n",
    "        self.cell_time_param = nn.Parameter(t_init)\n",
    "\n",
    "        # 2. Gamma (常数)\n",
    "        self.gamma_param = nn.Parameter(torch.zeros(1, n_isoforms))\n",
    "        if init_gamma is not None:\n",
    "            self.gamma_param.data.copy_(self._inverse_softplus(torch.from_numpy(init_gamma).float().unsqueeze(0)))\n",
    "\n",
    "        # 3. Networks for Alpha/Beta (z -> parameter)\n",
    "        self.alpha_fc = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim), nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, n_genes)\n",
    "        )\n",
    "        self.beta_fc = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim), nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, n_isoforms)\n",
    "        )\n",
    "        \n",
    "        # Initialization logic (omitted for brevity, same as before)\n",
    "        if init_alpha is not None:\n",
    "            inv_alpha = self._inverse_softplus(torch.from_numpy(init_alpha).float())\n",
    "            self.alpha_fc[-1].bias.data.copy_(inv_alpha)\n",
    "        if init_beta_iso is not None:\n",
    "            inv_beta = self._inverse_softplus(torch.from_numpy(init_beta_iso).float())\n",
    "            self.beta_fc[-1].bias.data.copy_(inv_beta)\n",
    "\n",
    "    @staticmethod\n",
    "    def _inverse_softplus(x):\n",
    "        return torch.log(torch.exp(x) - 1.0 + 1e-6)\n",
    "\n",
    "    def forward(self, z_final, cell_indices):\n",
    "        \"\"\"\n",
    "        z_final: [Batch, Latent] 细胞当前的潜在状态\n",
    "        cell_indices: [Batch] 用于取时间\n",
    "        \"\"\"\n",
    "        batch_size = z_final.shape[0]\n",
    "        \n",
    "        # 1. 获取这个 Batch 中每个细胞的总时间 T\n",
    "        T = F.softplus(self.cell_time_param[cell_indices]) # [Batch, 1]\n",
    "        \n",
    "        # 2. 构造虚拟历史 (Virtual History)\n",
    "        # 我们假设细胞是从 z=0 演化到 z=z_final 的\n",
    "        # 我们生成 n_steps 个时间点，代表 0% T, 10% T, ... 90% T\n",
    "        \n",
    "        # 生成插值系数: [0, 0.1, 0.2, ..., 0.9] (假设 n_steps=10)\n",
    "        steps_ratio = torch.linspace(0, 1 - 1/self.n_steps, self.n_steps, device=self.device)\n",
    "        \n",
    "        # 扩展 z: [Batch, Steps, Latent]\n",
    "        # z_history[b, s, :] = z_final[b, :] * steps_ratio[s]\n",
    "        # 这就模拟了细胞从不成熟(0)到成熟(z_final)的过程\n",
    "        z_history = torch.einsum('bl,s->bsl', z_final, steps_ratio)\n",
    "        \n",
    "        # 3. 并行计算历史时刻的 Alpha 和 Beta\n",
    "        # 输入维度: [Batch * Steps, Latent] -> 输出: [Batch * Steps, Genes]\n",
    "        # 这样 alpha 就随状态(也就是随时间)变化了！\n",
    "        flat_z = z_history.reshape(-1, z_final.shape[1])\n",
    "        \n",
    "        alpha_flat = F.softplus(self.alpha_fc(flat_z))\n",
    "        beta_iso_flat = F.softplus(self.beta_fc(flat_z))\n",
    "        \n",
    "        # Reshape 回 [Batch, Steps, Features]\n",
    "        alpha_seq = alpha_flat.reshape(batch_size, self.n_steps, self.n_genes)\n",
    "        beta_iso_seq = beta_iso_flat.reshape(batch_size, self.n_steps, self.n_isoforms)\n",
    "        \n",
    "        # 计算 Gene level beta\n",
    "        beta_gene_seq = torch.einsum('bsi,gi->bsg', beta_iso_seq, self.g2i_mask)\n",
    "        \n",
    "        # 获取 Gamma (constant)\n",
    "        gamma = F.softplus(self.gamma_param)\n",
    "        \n",
    "        # 4. 数值积分 (Euler Method, 最简单直观的 delta time 累加)\n",
    "        # 类似于你说的 delta time * alpha\n",
    "        \n",
    "        dt = T / self.n_steps # [Batch, 1] 每个 step 的时长\n",
    "        \n",
    "        # 初始化 u, s 为 0\n",
    "        u = torch.zeros(batch_size, self.n_genes, device=self.device)\n",
    "        s = torch.zeros(batch_size, self.n_isoforms, device=self.device)\n",
    "        \n",
    "        for i in range(self.n_steps):\n",
    "            # 当前时刻的参数\n",
    "            alpha_t = alpha_seq[:, i, :]\n",
    "            beta_gene_t = beta_gene_seq[:, i, :]\n",
    "            beta_iso_t = beta_iso_seq[:, i, :]\n",
    "            \n",
    "            # --- 物理方程 (Euler更新) ---\n",
    "            # 这一步完全符合你的想法： u_new = u_old + dt * rate\n",
    "            \n",
    "            # dU = Production - Degradation\n",
    "            du = alpha_t - beta_gene_t * u\n",
    "            \n",
    "            # dS = Splicing - Degradation\n",
    "            # 注意: S的来源是 beta_iso * u_gene\n",
    "            u_expanded = torch.matmul(u, self.g2i_mask)\n",
    "            ds = beta_iso_t * u_expanded - gamma * s\n",
    "            \n",
    "            # 更新状态\n",
    "            u = u + dt * du\n",
    "            s = s + dt * ds\n",
    "            \n",
    "            # 保证非负\n",
    "            u = F.relu(u)\n",
    "            s = F.relu(s)\n",
    "            \n",
    "        return {\n",
    "            \"u_hat\": u, \n",
    "            \"s_hat\": s,\n",
    "            \"t\": T,\n",
    "            \"alpha\": alpha_seq[:, -1, :], # 返回最后一步的alpha供参考\n",
    "            \"beta\": beta_iso_seq[:, -1, :],\n",
    "            \"gamma\": gamma\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fdbb683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda\n",
      "--- Starting Forward Pass ---\n",
      "\n",
      "✅ Forward pass successful!\n",
      "Reconstructed U shape: torch.Size([20, 10]) (Expected: 20, 10)\n",
      "Reconstructed S shape: torch.Size([20, 15]) (Expected: 20, 15)\n",
      "Inferred Time shape:   torch.Size([20, 1]) (Expected: 20, 1)\n",
      "数值检查通过: No NaNs detected.\n",
      "\n",
      "Example U_hat (first cell):\n",
      "[0.98614293 0.6515614  0.70129627 1.1449945  0.72132283]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1. 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Running on: {device}\")\n",
    "\n",
    "# 2. 定义维度 (模拟小规模数据)\n",
    "n_cells = 20\n",
    "n_genes = 10\n",
    "n_isoforms = 15\n",
    "latent_dim = 128\n",
    "hidden_dim = 256\n",
    "\n",
    "# 3. 构造必要的模拟数据\n",
    "# (A) Gene-to-Isoform Mask (必须项)\n",
    "# 逻辑：创建一个 [Genes, Isoforms] 的矩阵，每一列(isoform)只有一个1(属于某个gene)\n",
    "mask_np = np.zeros((n_genes, n_isoforms))\n",
    "# 简单起见，随机给每个 isoform 分配一个 gene\n",
    "for i in range(n_isoforms):\n",
    "    g_idx = np.random.randint(0, n_genes)\n",
    "    mask_np[g_idx, i] = 1\n",
    "g2i_mask = torch.from_numpy(mask_np)\n",
    "\n",
    "# (B) 初始化参数 (scvelo 模拟结果)\n",
    "# 注意形状：Time是(n_cells,), Alpha是(n_genes,), Beta/Gamma是(n_isoforms,)\n",
    "test_time = np.random.rand(n_cells) * 5.0 # 模拟时间 0-5\n",
    "test_alpha = np.random.rand(n_genes)\n",
    "test_beta_iso = np.random.rand(n_isoforms)\n",
    "test_gamma = np.random.rand(n_isoforms)\n",
    "\n",
    "# (C) 模拟输入 Latent z\n",
    "test_z = torch.randn(n_cells, latent_dim).to(device) # [Batch, 128]\n",
    "\n",
    "# (D) 模拟 Batch Indices (如果是全量测试，就是 range(n_cells))\n",
    "# 如果是 DataLoader 里的一个 batch，这里就是该 batch 对应的索引\n",
    "test_indices = torch.arange(n_cells).to(device)\n",
    "\n",
    "# 4. 实例化 Decoder\n",
    "# 注意：你需要确保你的 IsoveloDecoder 类定义在前面已经运行过\n",
    "decoder = IsoveloDecoder(\n",
    "    n_cells=n_cells,\n",
    "    n_genes=n_genes,\n",
    "    n_isoforms=n_isoforms,\n",
    "    g2i_mask=g2i_mask,       # <--- 关键新增\n",
    "    latent_dim=latent_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    n_steps=10,              # 数值积分步数\n",
    "    init_time=test_time,\n",
    "    init_alpha=test_alpha,\n",
    "    init_beta_iso=test_beta_iso,\n",
    "    init_gamma=test_gamma,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "# 5. 运行 Forward 测试\n",
    "print(\"--- Starting Forward Pass ---\")\n",
    "try:\n",
    "    # Forward 需要传入 indices 以获取对应的 Time\n",
    "    outputs = decoder(test_z, test_indices)\n",
    "    \n",
    "    # 6. 检查输出结果\n",
    "    u_hat = outputs[\"u_hat\"]\n",
    "    s_hat = outputs[\"s_hat\"]\n",
    "    pred_time = outputs[\"t\"]\n",
    "    \n",
    "    print(\"\\n✅ Forward pass successful!\")\n",
    "    print(f\"Reconstructed U shape: {u_hat.shape} (Expected: {n_cells}, {n_genes})\")\n",
    "    print(f\"Reconstructed S shape: {s_hat.shape} (Expected: {n_cells}, {n_isoforms})\")\n",
    "    print(f\"Inferred Time shape:   {pred_time.shape} (Expected: {n_cells}, 1)\")\n",
    "    \n",
    "    # 检查是否有 NaN (数值积分常见问题)\n",
    "    if torch.isnan(u_hat).any() or torch.isnan(s_hat).any():\n",
    "        print(\"⚠️ Warning: Output contains NaNs. Check initialization or learning rates.\")\n",
    "    else:\n",
    "        print(\"数值检查通过: No NaNs detected.\")\n",
    "        \n",
    "    # 查看一下实际的数据示例（确保非负）\n",
    "    print(f\"\\nExample U_hat (first cell):\\n{u_hat[0, :5].detach().cpu().numpy()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error during forward pass: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f80c142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'u_hat': tensor([[0.9861, 0.6516, 0.7013, 1.1450, 0.7213, 0.1793, 0.6613, 0.4312, 0.1813,\n",
       "          1.5473],\n",
       "         [0.6498, 0.4466, 0.5104, 0.7735, 0.5817, 0.1442, 0.5040, 0.4521, 0.1635,\n",
       "          1.0480],\n",
       "         [2.6094, 1.1398, 0.7589, 3.1038, 1.0989, 0.2259, 1.7275, 0.4090, 0.1932,\n",
       "          3.4930],\n",
       "         [1.2076, 0.7583, 0.6639, 1.5062, 0.9735, 0.2168, 0.7520, 0.4659, 0.1817,\n",
       "          1.7877],\n",
       "         [2.3933, 0.9522, 0.6311, 3.2229, 0.9823, 0.1757, 1.4936, 0.5275, 0.1734,\n",
       "          3.6760],\n",
       "         [1.1300, 0.6371, 0.7708, 1.1434, 0.6233, 0.2014, 0.6648, 0.3928, 0.1545,\n",
       "          1.6125],\n",
       "         [0.7795, 0.5358, 0.5507, 1.0127, 0.6285, 0.1635, 0.4810, 0.4568, 0.1901,\n",
       "          1.2098],\n",
       "         [1.6265, 1.0227, 0.6674, 2.0116, 0.8331, 0.2312, 1.0964, 0.5128, 0.1816,\n",
       "          2.3464],\n",
       "         [2.4238, 1.1571, 0.7659, 2.8902, 0.8844, 0.1796, 1.6040, 0.5028, 0.1894,\n",
       "          3.5638],\n",
       "         [2.2764, 1.2852, 0.6608, 2.6655, 1.0902, 0.1464, 1.7238, 0.4555, 0.1604,\n",
       "          3.0922],\n",
       "         [0.8952, 0.6651, 0.5937, 1.2498, 0.7722, 0.1607, 0.5802, 0.5116, 0.1623,\n",
       "          1.5359],\n",
       "         [0.7767, 0.4854, 0.5208, 0.9615, 0.6092, 0.1856, 0.4548, 0.4098, 0.1951,\n",
       "          1.1436],\n",
       "         [1.4848, 0.7524, 0.6043, 1.6129, 0.8423, 0.1973, 0.9283, 0.5484, 0.1611,\n",
       "          2.1193],\n",
       "         [2.1895, 0.8306, 0.7225, 2.4704, 1.1458, 0.1639, 1.4448, 0.5468, 0.2243,\n",
       "          2.9916],\n",
       "         [2.2782, 1.2158, 0.6533, 2.5482, 0.7457, 0.2365, 1.4605, 0.4400, 0.1777,\n",
       "          3.5109],\n",
       "         [1.1024, 0.6165, 0.6392, 1.3177, 0.6828, 0.2083, 0.6327, 0.4458, 0.1576,\n",
       "          1.6284],\n",
       "         [2.2637, 1.1189, 0.5724, 2.5153, 1.0191, 0.1868, 1.4310, 0.5624, 0.1488,\n",
       "          3.3593],\n",
       "         [1.8419, 1.1421, 1.0107, 2.4147, 0.9249, 0.2395, 1.4917, 0.6254, 0.1958,\n",
       "          2.7850],\n",
       "         [2.6474, 1.4445, 0.7085, 3.3078, 0.9099, 0.2020, 1.7306, 0.4474, 0.1272,\n",
       "          4.0472],\n",
       "         [1.6265, 0.9654, 0.7105, 1.8890, 0.9910, 0.2577, 0.9959, 0.6194, 0.1690,\n",
       "          2.4093]], device='cuda:0', grad_fn=<ReluBackward0>),\n",
       " 's_hat': tensor([[0.1412, 0.1426, 0.1584, 0.1799, 0.1292, 0.1859, 0.1512, 0.3459, 0.0756,\n",
       "          0.0235, 0.2216, 0.0789, 0.2035, 0.1082, 0.1898],\n",
       "         [0.1137, 0.0703, 0.0658, 0.0919, 0.0851, 0.1038, 0.0876, 0.2630, 0.0352,\n",
       "          0.0128, 0.1581, 0.0481, 0.1316, 0.0497, 0.1167],\n",
       "         [0.2774, 0.5331, 0.4062, 0.3674, 0.1582, 0.4172, 0.2217, 1.0920, 0.1911,\n",
       "          0.0542, 0.5258, 0.1083, 0.2646, 0.2015, 0.4194],\n",
       "         [0.1856, 0.2086, 0.2178, 0.1986, 0.1508, 0.2144, 0.1634, 0.5718, 0.1277,\n",
       "          0.0293, 0.2832, 0.0934, 0.2171, 0.1115, 0.2125],\n",
       "         [0.3937, 0.5475, 0.4790, 0.3191, 0.1554, 0.5525, 0.1781, 1.3841, 0.2250,\n",
       "          0.0655, 0.4751, 0.0879, 0.2372, 0.1821, 0.4336],\n",
       "         [0.1581, 0.1409, 0.1470, 0.1793, 0.1055, 0.1418, 0.1183, 0.4293, 0.0817,\n",
       "          0.0205, 0.2251, 0.0668, 0.1987, 0.0967, 0.2008],\n",
       "         [0.1111, 0.1164, 0.1294, 0.1255, 0.0918, 0.1034, 0.1072, 0.2586, 0.0465,\n",
       "          0.0162, 0.1791, 0.0663, 0.1389, 0.0571, 0.1473],\n",
       "         [0.2381, 0.2981, 0.2979, 0.2565, 0.1684, 0.2801, 0.1912, 0.7393, 0.1186,\n",
       "          0.0373, 0.3538, 0.0908, 0.2298, 0.1780, 0.2875],\n",
       "         [0.3167, 0.4822, 0.4853, 0.3803, 0.1742, 0.5283, 0.2356, 1.2428, 0.2307,\n",
       "          0.0627, 0.5605, 0.0902, 0.2853, 0.2056, 0.4140],\n",
       "         [0.3306, 0.4625, 0.3743, 0.3238, 0.1387, 0.4209, 0.1770, 1.1519, 0.2094,\n",
       "          0.0634, 0.4323, 0.0983, 0.2743, 0.1772, 0.3721],\n",
       "         [0.1584, 0.1205, 0.1906, 0.1470, 0.1034, 0.1370, 0.1235, 0.3684, 0.0550,\n",
       "          0.0177, 0.2006, 0.0581, 0.1259, 0.0812, 0.1872],\n",
       "         [0.1241, 0.0790, 0.0944, 0.0951, 0.0936, 0.1056, 0.1205, 0.2663, 0.0463,\n",
       "          0.0141, 0.1509, 0.0620, 0.1293, 0.0569, 0.1478],\n",
       "         [0.1976, 0.2598, 0.2469, 0.2614, 0.1510, 0.2452, 0.1850, 0.6976, 0.1191,\n",
       "          0.0383, 0.2965, 0.0786, 0.2362, 0.1448, 0.3216],\n",
       "         [0.3225, 0.3343, 0.3657, 0.3219, 0.2052, 0.3993, 0.2758, 0.9409, 0.1543,\n",
       "          0.0485, 0.4916, 0.1150, 0.2537, 0.1332, 0.3968],\n",
       "         [0.3339, 0.4388, 0.3707, 0.3290, 0.1567, 0.3464, 0.2140, 1.0343, 0.1767,\n",
       "          0.0504, 0.4104, 0.1006, 0.2964, 0.1899, 0.4382],\n",
       "         [0.1490, 0.1896, 0.1586, 0.1880, 0.1150, 0.1561, 0.1379, 0.4080, 0.0791,\n",
       "          0.0306, 0.2370, 0.0758, 0.1799, 0.0975, 0.2515],\n",
       "         [0.3557, 0.3876, 0.3529, 0.2790, 0.1560, 0.3922, 0.1818, 1.1172, 0.2063,\n",
       "          0.0612, 0.4157, 0.0860, 0.2237, 0.1833, 0.4209],\n",
       "         [0.3317, 0.4041, 0.3771, 0.3379, 0.1596, 0.4039, 0.2204, 0.9495, 0.1507,\n",
       "          0.0479, 0.4192, 0.0963, 0.3190, 0.1555, 0.4601],\n",
       "         [0.2819, 0.6244, 0.3599, 0.4760, 0.1207, 0.4374, 0.2160, 1.3051, 0.2147,\n",
       "          0.0771, 0.4109, 0.0873, 0.2737, 0.2151, 0.4595],\n",
       "         [0.3036, 0.2740, 0.2978, 0.2741, 0.1462, 0.3401, 0.2101, 0.8143, 0.1643,\n",
       "          0.0473, 0.3754, 0.0837, 0.2325, 0.1705, 0.3694]], device='cuda:0',\n",
       "        grad_fn=<ReluBackward0>),\n",
       " 't': tensor([[1.8198],\n",
       "         [1.2534],\n",
       "         [4.4430],\n",
       "         [2.3463],\n",
       "         [4.6230],\n",
       "         [1.8446],\n",
       "         [1.4615],\n",
       "         [2.8387],\n",
       "         [4.6683],\n",
       "         [4.2852],\n",
       "         [1.7434],\n",
       "         [1.3921],\n",
       "         [2.6054],\n",
       "         [3.6951],\n",
       "         [3.8726],\n",
       "         [1.9841],\n",
       "         [4.1164],\n",
       "         [3.5656],\n",
       "         [4.9068],\n",
       "         [3.1941]], device='cuda:0', grad_fn=<SoftplusBackward0>),\n",
       " 'alpha': tensor([[0.5135, 0.4509, 0.9985, 0.5939, 0.5770, 0.2390, 0.3727, 0.5200, 0.5680,\n",
       "          0.9282],\n",
       "         [0.4618, 0.3809, 0.8211, 0.5708, 0.7077, 0.1796, 0.4470, 0.6427, 0.4937,\n",
       "          0.9035],\n",
       "         [0.5897, 0.4681, 0.8448, 0.7349, 0.6137, 0.1953, 0.4186, 0.4480, 0.5426,\n",
       "          0.7895],\n",
       "         [0.4603, 0.4162, 0.7660, 0.6124, 0.7740, 0.2420, 0.2837, 0.4888, 0.5392,\n",
       "          0.7551],\n",
       "         [0.4519, 0.3798, 0.7238, 0.7246, 0.7020, 0.1778, 0.2928, 0.6851, 0.4442,\n",
       "          0.8233],\n",
       "         [0.6536, 0.4158, 1.0624, 0.5730, 0.5585, 0.2458, 0.3604, 0.4368, 0.4430,\n",
       "          0.9770],\n",
       "         [0.4934, 0.4569, 0.8179, 0.7120, 0.5788, 0.1876, 0.3043, 0.5834, 0.5259,\n",
       "          0.8770],\n",
       "         [0.5739, 0.5520, 0.7725, 0.7500, 0.6056, 0.2511, 0.4151, 0.5673, 0.5558,\n",
       "          0.8799],\n",
       "         [0.4722, 0.4154, 0.8483, 0.5591, 0.5783, 0.1936, 0.3306, 0.6042, 0.5519,\n",
       "          0.7456],\n",
       "         [0.4879, 0.5056, 0.7586, 0.5790, 0.6740, 0.1680, 0.4512, 0.5134, 0.4228,\n",
       "          0.6702],\n",
       "         [0.4523, 0.4702, 0.7434, 0.7622, 0.7000, 0.1710, 0.3053, 0.6615, 0.4368,\n",
       "          0.9900],\n",
       "         [0.5391, 0.3730, 0.7648, 0.7020, 0.6356, 0.2291, 0.3021, 0.5372, 0.5572,\n",
       "          0.8812],\n",
       "         [0.5596, 0.3933, 0.8385, 0.5713, 0.6592, 0.2223, 0.3608, 0.5378, 0.4982,\n",
       "          0.8411],\n",
       "         [0.6149, 0.2920, 0.8406, 0.6694, 0.6927, 0.1363, 0.4278, 0.6105, 0.7087,\n",
       "          0.8410],\n",
       "         [0.5928, 0.5376, 0.8792, 0.6434, 0.5110, 0.2112, 0.3937, 0.5243, 0.4961,\n",
       "          1.0512],\n",
       "         [0.5371, 0.4085, 0.8758, 0.6572, 0.5204, 0.2345, 0.2857, 0.4549, 0.4674,\n",
       "          0.8661],\n",
       "         [0.5200, 0.4071, 0.6767, 0.5550, 0.6557, 0.1909, 0.3356, 0.5674, 0.4260,\n",
       "          0.8606],\n",
       "         [0.4641, 0.5365, 1.1654, 0.6819, 0.6107, 0.1909, 0.4861, 0.6954, 0.5412,\n",
       "          0.7832],\n",
       "         [0.5074, 0.5984, 0.9218, 0.6717, 0.5993, 0.2001, 0.3453, 0.4152, 0.3800,\n",
       "          0.8671],\n",
       "         [0.4456, 0.3977, 0.8291, 0.5159, 0.6426, 0.2578, 0.2691, 0.6501, 0.5019,\n",
       "          0.7397]], device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " 'beta': tensor([[0.3535, 0.3239, 0.3527, 0.3398, 0.7941, 0.4455, 0.8194, 0.5482, 0.4058,\n",
       "          0.1382, 1.0295, 0.4926, 0.4986, 0.7215, 0.3472],\n",
       "         [0.4558, 0.3114, 0.1877, 0.3056, 0.7425, 0.3799, 0.6729, 0.8285, 0.3356,\n",
       "          0.1432, 1.2555, 0.3977, 0.5768, 0.5445, 0.4055],\n",
       "         [0.4002, 0.3482, 0.3810, 0.3271, 0.6120, 0.3501, 0.6288, 0.5182, 0.2684,\n",
       "          0.0896, 1.1022, 0.4670, 0.3697, 0.5047, 0.3877],\n",
       "         [0.3510, 0.3218, 0.3450, 0.2869, 0.7851, 0.3283, 0.6781, 0.5706, 0.4822,\n",
       "          0.1049, 1.0029, 0.5045, 0.4494, 0.4520, 0.3083],\n",
       "         [0.5014, 0.3967, 0.3818, 0.3108, 0.6599, 0.4169, 0.5058, 0.7212, 0.3886,\n",
       "          0.1357, 0.9931, 0.4018, 0.3786, 0.5207, 0.4574],\n",
       "         [0.4433, 0.3143, 0.3352, 0.3063, 0.6677, 0.3158, 0.6333, 0.7954, 0.4126,\n",
       "          0.1023, 1.1796, 0.4361, 0.4455, 0.5574, 0.3435],\n",
       "         [0.3441, 0.4036, 0.3834, 0.3488, 0.5997, 0.2813, 0.6376, 0.5921, 0.3415,\n",
       "          0.1347, 1.0351, 0.4659, 0.4811, 0.4672, 0.4102],\n",
       "         [0.3755, 0.3095, 0.3751, 0.3259, 0.8145, 0.3284, 0.7155, 0.6766, 0.2808,\n",
       "          0.1028, 1.0896, 0.4410, 0.4130, 0.6481, 0.3667],\n",
       "         [0.3965, 0.2931, 0.4040, 0.3272, 0.6946, 0.4064, 0.6795, 0.6782, 0.3839,\n",
       "          0.1224, 1.1610, 0.3794, 0.3938, 0.6000, 0.3651],\n",
       "         [0.4724, 0.2777, 0.3251, 0.3185, 0.6135, 0.3499, 0.5439, 0.5793, 0.4457,\n",
       "          0.1642, 0.9831, 0.4910, 0.4376, 0.5996, 0.3799],\n",
       "         [0.3930, 0.2731, 0.4417, 0.3116, 0.6579, 0.2724, 0.6950, 0.6035, 0.3069,\n",
       "          0.1100, 1.0259, 0.3583, 0.3248, 0.5783, 0.4198],\n",
       "         [0.4657, 0.2874, 0.2856, 0.2646, 0.6536, 0.3418, 0.8141, 0.6905, 0.3365,\n",
       "          0.1085, 0.8687, 0.4495, 0.4863, 0.4519, 0.4674],\n",
       "         [0.3025, 0.3714, 0.3107, 0.3902, 0.8186, 0.2979, 0.8220, 0.7035, 0.3735,\n",
       "          0.1374, 1.0432, 0.4169, 0.4854, 0.6076, 0.4975],\n",
       "         [0.4298, 0.3077, 0.3301, 0.3213, 0.7857, 0.3424, 0.8347, 0.5139, 0.3394,\n",
       "          0.1294, 1.0900, 0.4597, 0.3849, 0.4228, 0.4233],\n",
       "         [0.5253, 0.3016, 0.3781, 0.3469, 0.6720, 0.3112, 0.6960, 0.7421, 0.2851,\n",
       "          0.0931, 0.9499, 0.4742, 0.4921, 0.4989, 0.4992],\n",
       "         [0.3379, 0.4260, 0.3043, 0.3387, 0.6950, 0.2950, 0.7215, 0.6206, 0.3354,\n",
       "          0.1564, 1.1049, 0.4795, 0.4170, 0.4958, 0.4858],\n",
       "         [0.4464, 0.2617, 0.2672, 0.2962, 0.7625, 0.2824, 0.6165, 0.6153, 0.3849,\n",
       "          0.1364, 1.0285, 0.4461, 0.3906, 0.5343, 0.5087],\n",
       "         [0.4083, 0.3154, 0.3253, 0.2664, 0.6419, 0.3328, 0.7033, 0.6341, 0.2583,\n",
       "          0.1000, 1.0015, 0.4164, 0.3836, 0.4052, 0.3985],\n",
       "         [0.3693, 0.3187, 0.2658, 0.4542, 0.6260, 0.3143, 0.8445, 0.6734, 0.2936,\n",
       "          0.1458, 0.9598, 0.5200, 0.4009, 0.5643, 0.4351],\n",
       "         [0.4022, 0.2532, 0.2727, 0.3017, 0.6796, 0.3112, 0.7987, 0.5687, 0.3393,\n",
       "          0.1091, 1.0898, 0.4034, 0.3730, 0.4863, 0.4396]], device='cuda:0',\n",
       "        grad_fn=<SliceBackward0>),\n",
       " 'gamma': tensor([[0.6154, 0.4956, 0.2747, 0.5619, 0.7442, 0.1964, 0.5067, 0.3443, 0.1067,\n",
       "          0.1902, 0.2206, 0.8214, 0.9925, 0.4811, 0.5904]], device='cuda:0',\n",
       "        grad_fn=<SoftplusBackward0>)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76f26d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import scvelo as scv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess_and_initialize_scvelo(\n",
    "    adata, \n",
    "    isoform_key=\"isoform_counts\", \n",
    "    min_isoform_counts=10, \n",
    "    min_isoform_prop=0.05, \n",
    "    n_top_genes=2000\n",
    "):\n",
    "    \"\"\"\n",
    "    预处理 Pipeline：\n",
    "    1. 清洗 Isoforms (去除低表达、低比例)。\n",
    "    2. 聚合 Isoforms 得到 Gene Spliced Counts。\n",
    "    3. 清洗 Genes (保留高变基因 OR Isoform比例高变基因)。\n",
    "    4. 运行 scVelo dynamical mode。\n",
    "    5. 返回 VAE 需要的初始化参数。\n",
    "    \n",
    "    参数:\n",
    "    adata: 包含 layers['unspliced'] 和 obsm[isoform_key]\n",
    "    isoform_key: 存储 isoform count 的 key\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"--- 1. Mapping Isoforms to Genes ---\")\n",
    "    # 假设 isoform 的名字格式为 \"GeneName-IsoformID\" 或者你有办法从 adata.uns 中获取\n",
    "    # 这里我们假设 adata.obsm[isoform_key] 是一个 DataFrame，列名是 Isoform 名字\n",
    "    # 如果是 numpy array，你需要额外传入 isoform_names\n",
    "    \n",
    "    if isinstance(adata.obsm[isoform_key], pd.DataFrame):\n",
    "        isoform_df = adata.obsm[isoform_key]\n",
    "    else:\n",
    "        # 如果是 numpy/sparse，必须有对应的名字，这里假设存在 adata.uns['isoform_names']\n",
    "        isoform_df = pd.DataFrame(\n",
    "            adata.obsm[isoform_key].toarray() if sp.issparse(adata.obsm[isoform_key]) else adata.obsm[isoform_key],\n",
    "            index=adata.obs_names,\n",
    "            columns=adata.uns.get('isoform_names', [f\"Iso_{i}\" for i in range(adata.obsm[isoform_key].shape[1])])\n",
    "        )\n",
    "\n",
    "    # 建立映射: 假设 isoform 名字包含 gene 名字 (e.g., \"TP53-001\")\n",
    "    # 如果你的数据结构不同，请修改这里的 mapping 逻辑\n",
    "    # 比如: gene_map = {iso: gene for iso, gene in ...}\n",
    "    # 这里为了通用性，我们假设 isoform name 能够 parse 出 gene name，或者我们先简单处理：\n",
    "    # **重要**：实际项目中你需要一个确定的 Gene-Isoform 对应表。\n",
    "    # 这里我们做一个假设示例：假设我们已经有了 g2i_mapping\n",
    "    # 为了代码能跑，这里我需要你提供 mapping，或者我帮你生成一个 dummy 的\n",
    "    # 实际使用请替换为: gene_of_isoform = parse_gene_from_isoform(iso_name)\n",
    "    \n",
    "    # 暂时跳过复杂的 name parsing，假设 adata.var_names 涵盖了所有基因\n",
    "    # 我们需要构建一个 Mask [n_genes, n_isoforms]\n",
    "    isoform_names = isoform_df.columns\n",
    "    gene_names = adata.var_names\n",
    "    \n",
    "    # [用户需自定义] 这里是一个占位符，请替换为真实的映射逻辑\n",
    "    # 比如: gene_name = iso_name.split('-')[0]\n",
    "    # 下面代码假设 isoform_names 里包含 gene 信息\n",
    "    isoform_to_gene = {} \n",
    "    for iso in isoform_names:\n",
    "        # ⚠️ 请修改这里：根据你的数据格式提取 Gene Name\n",
    "        # 示例：如果是 \"GeneA_Iso1\"，则 split('_')[0]\n",
    "        # 这里尝试直接在 adata.var_names 里找匹配 (较慢，仅作演示)\n",
    "        found = False\n",
    "        for g in gene_names:\n",
    "            if g in iso: # 这是一个很弱的匹配，请务必用精确逻辑替换\n",
    "                isoform_to_gene[iso] = g\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            isoform_to_gene[iso] = None # 标记为删除\n",
    "\n",
    "    print(\"--- 2. Filtering Isoforms ---\")\n",
    "    # A. 表达量过滤\n",
    "    total_iso_counts = isoform_df.sum(axis=0)\n",
    "    valid_iso_mask = total_iso_counts > min_isoform_counts\n",
    "    \n",
    "    # B. 比例过滤 (Proportion)\n",
    "    # 先计算 Gene total counts\n",
    "    gene_spliced_sum = pd.DataFrame(0.0, index=adata.obs_names, columns=gene_names)\n",
    "    \n",
    "    # 加速聚合 (实际应使用矩阵乘法，这里用 pandas 演示逻辑)\n",
    "    # 构建矩阵映射\n",
    "    g2i_mat = np.zeros((len(gene_names), len(isoform_names)))\n",
    "    for i, iso in enumerate(isoform_names):\n",
    "        g_name = isoform_to_gene.get(iso)\n",
    "        if g_name is not None:\n",
    "            g_idx = adata.var_names.get_loc(g_name)\n",
    "            g2i_mat[g_idx, i] = 1\n",
    "            \n",
    "    # 计算 Gene Spliced Counts (用于 scvelo)\n",
    "    # S_gene = I_iso @ Mask.T\n",
    "    I_mat = isoform_df.values\n",
    "    S_gene_mat = I_mat @ g2i_mat.T\n",
    "    \n",
    "    # 计算每个 isoform 的全局平均 proportion\n",
    "    # Prop_i = Sum(I_i) / Sum(S_gene_of_i)\n",
    "    avg_proportions = []\n",
    "    isoforms_to_keep = []\n",
    "    \n",
    "    for i, iso in enumerate(isoform_names):\n",
    "        if not valid_iso_mask[i]: continue\n",
    "        \n",
    "        g_name = isoform_to_gene.get(iso)\n",
    "        if g_name is None: continue\n",
    "        \n",
    "        g_idx = adata.var_names.get_loc(g_name)\n",
    "        \n",
    "        # 计算比例\n",
    "        iso_sum = I_mat[:, i].sum()\n",
    "        gene_sum = S_gene_mat[:, g_idx].sum()\n",
    "        \n",
    "        if gene_sum == 0: prop = 0\n",
    "        else: prop = iso_sum / gene_sum\n",
    "        \n",
    "        if prop > min_isoform_prop:\n",
    "            isoforms_to_keep.append(iso)\n",
    "            avg_proportions.append(prop)\n",
    "            \n",
    "    print(f\"Kept {len(isoforms_to_keep)} / {len(isoform_names)} isoforms.\")\n",
    "    \n",
    "    # 更新 adata.obsm\n",
    "    adata.obsm[isoform_key] = isoform_df[isoforms_to_keep]\n",
    "    # 更新 Mask (G x I_new)\n",
    "    # 重建 g2i_mask 对应新的 isoforms\n",
    "    final_isoforms = isoforms_to_keep\n",
    "    final_g2i_mask = np.zeros((len(gene_names), len(final_isoforms)))\n",
    "    \n",
    "    isoform_gene_map_final = [isoform_to_gene[iso] for iso in final_isoforms]\n",
    "    \n",
    "    for i, g_name in enumerate(isoform_gene_map_final):\n",
    "        g_idx = adata.var_names.get_loc(g_name)\n",
    "        final_g2i_mask[g_idx, i] = 1\n",
    "        \n",
    "    final_g2i_mask_tensor = torch.from_numpy(final_g2i_mask).float()\n",
    "\n",
    "    print(\"--- 3. Constructing Gene-Level Data for scVelo ---\")\n",
    "    # scVelo 需要 layers['spliced'] 和 layers['unspliced']\n",
    "    # Spliced 来自 Isoform 的聚合\n",
    "    S_gene_final = adata.obsm[isoform_key].values @ final_g2i_mask.T\n",
    "    adata.layers['spliced'] = sp.csr_matrix(S_gene_final)\n",
    "    \n",
    "    # 确保 unspliced 也是 sparse\n",
    "    if not sp.issparse(adata.layers['unspliced']):\n",
    "        adata.layers['unspliced'] = sp.csr_matrix(adata.layers['unspliced'])\n",
    "\n",
    "    print(\"--- 4. Filtering Genes (Expression Var OR Isoform Var) ---\")\n",
    "    # 1. 常规 HVG (基于 Count)\n",
    "    scv.pp.filter_genes(adata, min_shared_counts=20)\n",
    "    scv.pp.normalize_per_cell(adata)\n",
    "    scv.pp.filter_genes_dispersion(adata, n_top_genes=n_top_genes)\n",
    "    hvg_genes = set(adata.var_names[adata.var['highly_variable']])\n",
    "    \n",
    "    # 2. Isoform Switch Genes (基于 Proportion Variance)\n",
    "    # 计算每个细胞中，每个 Gene 下 Isoform 分布的熵或方差，这里用简单的 proportion 方差\n",
    "    # 如果一个基因的 Isoform 比例在不同细胞间变化大，则保留该基因\n",
    "    # 为了简化，我们只保留那些已经在 isoform 过滤步骤中留下了至少 2 个 isoform 的基因\n",
    "    iso_counts_per_gene = final_g2i_mask.sum(axis=1) # [n_genes]\n",
    "    multi_iso_genes = adata.var_names[iso_counts_per_gene > 1]\n",
    "    \n",
    "    # 合并保留列表\n",
    "    genes_to_keep = list(hvg_genes.union(set(multi_iso_genes)))\n",
    "    adata = adata[:, genes_to_keep].copy()\n",
    "    \n",
    "    # 同时需要切分 g2i_mask 对应剩下的 genes\n",
    "    # 这是一个痛点：adata 切分后 var_names 变了，mask 也要变\n",
    "    # 重新构建 mask (快速版)\n",
    "    # 更好的方法是在 Dataset init 里做，但这里需要给 scvelo 跑\n",
    "    \n",
    "    print(f\"Final Genes: {adata.n_vars}, Final Isoforms: {len(final_isoforms)}\")\n",
    "\n",
    "    print(\"--- 5. Running scVelo (Dynamical Mode) ---\")\n",
    "    scv.pp.moments(adata, n_pcs=30, n_neighbors=30)\n",
    "    \n",
    "    # 核心：使用 dynamical model 恢复参数\n",
    "    scv.tl.recover_dynamics(adata, var_names='all', n_jobs=8)\n",
    "    \n",
    "    # 计算 velocity 和 latent time\n",
    "    scv.tl.velocity(adata, mode='dynamical')\n",
    "    scv.tl.latent_time(adata)\n",
    "    \n",
    "    print(\"--- 6. Extracting Parameters for Initialization ---\")\n",
    "    # 提取参数\n",
    "    # scVelo 的 fit_alpha, fit_beta, fit_gamma 是 Gene level 的\n",
    "    # 它们可能包含 NaN (如果 fitting 失败)，需要填充\n",
    "    \n",
    "    def get_param(key, default=1.0):\n",
    "        val = adata.var[key].values\n",
    "        # 填充 NaN\n",
    "        val = np.nan_to_num(val, nan=default)\n",
    "        return val.astype(np.float32)\n",
    "\n",
    "    init_alpha_g = get_param('fit_alpha')\n",
    "    init_beta_g = get_param('fit_beta')\n",
    "    init_gamma_g = get_param('fit_gamma')\n",
    "    \n",
    "    init_time = adata.obs['latent_time'].values.astype(np.float32)\n",
    "    # scVelo latent time 是 [0, 1]，可能需要 rescale 到 [0, 20] 左右以配合 ODE\n",
    "    init_time = init_time * 20.0 \n",
    "\n",
    "    # 计算 Isoform Level 的 Beta 和 Gamma\n",
    "    # 逻辑：Beta_iso = Beta_gene * avg_proportion\n",
    "    # 逻辑：Gamma_iso = Gamma_gene (假设降解率近似) 或者也是 * proportion?\n",
    "    # 通常降解是分子特有的。但如果没有 isoform specific 数据，假设 Gamma_iso ≈ Gamma_gene 是合理的起点，\n",
    "    # 或者假设 Beta_iso * U = S_iso * Gamma_iso (稳态假设) -> Gamma_iso = Beta_iso * U / S_iso\n",
    "    # 既然你要求 \"gamma同理\" (isoform proportion * gene gamma)，我们按你的要求做：\n",
    "    \n",
    "    # 我们需要知道当前 adata 的 genes 对应的 isoforms 的全局比例\n",
    "    # 注意：此时 adata 已经 filter 过了，mask 也要对应切片\n",
    "    \n",
    "    # 1. 对齐 Mask 到当前的 adata.var_names\n",
    "    current_genes = adata.var_names\n",
    "    # 重新映射 final_isoforms 到 current_genes\n",
    "    subset_mask = np.zeros((len(current_genes), len(final_isoforms)))\n",
    "    for i, iso in enumerate(final_isoforms):\n",
    "        g_name = isoform_gene_map_final[i]\n",
    "        if g_name in current_genes:\n",
    "            g_idx = adata.var_names.get_loc(g_name)\n",
    "            subset_mask[g_idx, i] = 1\n",
    "    \n",
    "    subset_mask_tensor = torch.from_numpy(subset_mask).float()\n",
    "    \n",
    "    # 2. 计算平均 Proportion (Global)\n",
    "    # I: [Cells, Isoforms], S_g: [Cells, Genes]\n",
    "    # 这是一个全局常数向量 [n_isoforms]\n",
    "    I_val = adata.obsm[isoform_key].values # 注意：这里要是 subset 后的 isoforms\n",
    "    # 上面代码没有 inplace 更新 adata.obsm 的列，这里需要注意\n",
    "    # 修正：上面 adata.obsm[isoform_key] 已经是 filtered isoforms 了\n",
    "    \n",
    "    total_I = I_val.sum(axis=0) # [n_isoforms]\n",
    "    \n",
    "    # 映射 Gene Sum 到 Isoform 维度\n",
    "    # total_G[j] = Sum of gene counts for gene corresponding to isoform j\n",
    "    gene_counts = (I_val @ subset_mask.T).sum(axis=0) # [n_genes]\n",
    "    \n",
    "    # 扩展 gene_counts 到 isoform 维度\n",
    "    # iso_gene_total = gene_counts[gene_index_of_isoform]\n",
    "    # 利用矩阵乘法: [n_genes] @ [n_genes, n_isoforms] -> [n_isoforms]\n",
    "    # 但 mask 是 0/1，可以直接乘\n",
    "    iso_gene_total = gene_counts @ subset_mask\n",
    "    \n",
    "    iso_proportions = np.divide(total_I, iso_gene_total, out=np.zeros_like(total_I), where=iso_gene_total!=0)\n",
    "    \n",
    "    # 3. 计算 Init Values\n",
    "    # init_beta_g: [n_genes]\n",
    "    # 扩展到 isoform: [n_isoforms]\n",
    "    beta_g_expanded = init_beta_g @ subset_mask\n",
    "    gamma_g_expanded = init_gamma_g @ subset_mask\n",
    "    \n",
    "    init_beta_iso = beta_g_expanded * iso_proportions\n",
    "    init_gamma_iso = gamma_g_expanded * iso_proportions # 按你要求的逻辑\n",
    "    \n",
    "    return {\n",
    "        \"adata\": adata,\n",
    "        \"g2i_mask\": subset_mask_tensor,\n",
    "        \"init_time\": init_time,\n",
    "        \"init_alpha\": init_alpha_g,\n",
    "        \"init_beta_iso\": init_beta_iso,\n",
    "        \"init_gamma\": init_gamma_iso,\n",
    "        \"final_isoforms\": final_isoforms\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39b28092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Mapping Isoforms to Genes ---\n",
      "--- 2. Filtering Isoforms ---\n",
      "Kept 1 / 3468 isoforms.\n",
      "--- 3. Constructing Gene-Level Data for scVelo ---\n",
      "--- 4. Filtering Genes (Expression Var OR Isoform Var) ---\n",
      "Filtered out 999 genes that are detected 20 counts (shared).\n",
      "Normalized count data: X, spliced, unspliced.\n",
      "Skip filtering by dispersion since number of variables are less than `n_top_genes`.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'highly_variable'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\shizh\\.conda\\envs\\IsoVelo_test\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'highly_variable'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 假设 adata 已经加载，并且 adata.obsm['isoform_counts'] 存在\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 重要：你需要确保知道 isoform 对应的 gene，这里需要你根据实际情况修改 isoform_to_gene 的逻辑\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_and_initialize_scvelo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43madata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43misoform_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43misoform_counts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_isoform_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_isoform_prop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m processed_adata \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m g2i_mask \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mg2i_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[13], line 153\u001b[0m, in \u001b[0;36mpreprocess_and_initialize_scvelo\u001b[1;34m(adata, isoform_key, min_isoform_counts, min_isoform_prop, n_top_genes)\u001b[0m\n\u001b[0;32m    151\u001b[0m scv\u001b[38;5;241m.\u001b[39mpp\u001b[38;5;241m.\u001b[39mnormalize_per_cell(adata)\n\u001b[0;32m    152\u001b[0m scv\u001b[38;5;241m.\u001b[39mpp\u001b[38;5;241m.\u001b[39mfilter_genes_dispersion(adata, n_top_genes\u001b[38;5;241m=\u001b[39mn_top_genes)\n\u001b[1;32m--> 153\u001b[0m hvg_genes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(adata\u001b[38;5;241m.\u001b[39mvar_names[\u001b[43madata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhighly_variable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m])\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# 2. Isoform Switch Genes (基于 Proportion Variance)\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# 计算每个细胞中，每个 Gene 下 Isoform 分布的熵或方差，这里用简单的 proportion 方差\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# 如果一个基因的 Isoform 比例在不同细胞间变化大，则保留该基因\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# 为了简化，我们只保留那些已经在 isoform 过滤步骤中留下了至少 2 个 isoform 的基因\u001b[39;00m\n\u001b[0;32m    159\u001b[0m iso_counts_per_gene \u001b[38;5;241m=\u001b[39m final_g2i_mask\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# [n_genes]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shizh\\.conda\\envs\\IsoVelo_test\\lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4113\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4115\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\shizh\\.conda\\envs\\IsoVelo_test\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3817\u001b[0m     ):\n\u001b[0;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'highly_variable'"
     ]
    }
   ],
   "source": [
    "# 假设 adata 已经加载，并且 adata.obsm['isoform_counts'] 存在\n",
    "# 重要：你需要确保知道 isoform 对应的 gene，这里需要你根据实际情况修改 isoform_to_gene 的逻辑\n",
    "\n",
    "results = preprocess_and_initialize_scvelo(\n",
    "    adata, \n",
    "    isoform_key=\"isoform_counts\",\n",
    "    min_isoform_counts=20,\n",
    "    min_isoform_prop=0.05\n",
    ")\n",
    "\n",
    "processed_adata = results['adata']\n",
    "g2i_mask = results['g2i_mask']\n",
    "\n",
    "# 实例化你的 VAE Decoder\n",
    "decoder = IsoveloDecoder(\n",
    "    n_cells=processed_adata.n_obs,\n",
    "    n_genes=processed_adata.n_vars,\n",
    "    n_isoforms=len(results['final_isoforms']),\n",
    "    g2i_mask=g2i_mask,\n",
    "    init_time=results['init_time'],\n",
    "    init_alpha=results['init_alpha'],\n",
    "    init_beta_iso=results['init_beta_iso'],\n",
    "    init_gamma=results['init_gamma'],\n",
    "    device=device\n",
    ").to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
